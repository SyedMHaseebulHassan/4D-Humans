{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH6h3ljStKEV"
      },
      "source": [
        "# 4DHumans Demo Notebook\n",
        "This a demo notebook for our paper \"4DHumans: Reconstructing and Tracking Humans with Transformers\".\n",
        "\n",
        "<p align=\"left\"><img src=\"https://github.com/shubham-goel/4D-Humans/raw/main/assets/teaser.png\" width=\"800\"></p>\n",
        "\n",
        "<p align=\"left\"><img src=\"https://github.com/brjathu/PHALP/raw/master/assets/imgs/teaser.gif\" width=\"800\"></p>\n",
        "\n",
        "Project webpage: https://shubham-goel.github.io/4dhumans/\n",
        "\n",
        "Github repo: https://github.com/shubham-goel/4D-Humans\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Enable the GPU Runtime (Runtime > Change Runtime Type > GPU)\n",
        "2. Clone the repository and install depencencies\n",
        "3. Run the demo\n",
        "4. Visualize the video\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Grc-NDsvJ2d"
      },
      "source": [
        "# Clone the repository and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nHlxjgrdtePu"
      },
      "outputs": [],
      "source": [
        "# Clone the main repo\n",
        "%%capture\n",
        "! git clone https://github.com/shubham-goel/4D-Humans.git 4D-Humans\n",
        "%cd 4D-Humans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urCqVANctz2s",
        "outputId": "cf965c0d-038e-44ce-a427-5d669da23421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Obtaining file:///content/4D-Humans\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chumpy@ git+https://github.com/mattloper/chumpy (from hmr2==0.0.0)\n",
            "  Cloning https://github.com/mattloper/chumpy to /tmp/pip-install-_rfnf8r3/chumpy_d66dd803750545dea787749798bcfd62\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mattloper/chumpy /tmp/pip-install-_rfnf8r3/chumpy_d66dd803750545dea787749798bcfd62\n",
            "  Resolved https://github.com/mattloper/chumpy to commit 580566eafc9ac68b2614b64d6f7aaa84eebb70da\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (5.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (0.24.0+cu126)\n",
            "Collecting pytorch-lightning (from hmr2==0.0.0)\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting smplx==0.1.28 (from hmr2==0.0.0)\n",
            "  Downloading smplx-0.1.28-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pyrender (from hmr2==0.0.0)\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (4.13.0.90)\n",
            "Collecting yacs (from hmr2==0.0.0)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (0.25.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (0.8.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (1.0.24)\n",
            "Collecting webdataset (from hmr2==0.0.0)\n",
            "  Downloading webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from hmr2==0.0.0) (2.2.2)\n",
            "Collecting detectron2@ git+https://github.com/facebookresearch/detectron2 (from hmr2==0.0.0)\n",
            "  Cloning https://github.com/facebookresearch/detectron2 to /tmp/pip-install-_rfnf8r3/detectron2_272a610754324224a197bd9b7e9ea7df\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2 /tmp/pip-install-_rfnf8r3/detectron2_272a610754324224a197bd9b7e9ea7df\n",
            "  Resolved https://github.com/facebookresearch/detectron2 to commit fd27788985af0f4ca800bca563acdb700bb890e2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->hmr2==0.0.0) (3.5.0)\n",
            "Requirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from chumpy@ git+https://github.com/mattloper/chumpy->hmr2==0.0.0) (1.16.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from chumpy@ git+https://github.com/mattloper/chumpy->hmr2==0.0.0) (1.17.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (2.0.11)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (3.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (2.19.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from yacs->hmr2==0.0.0) (6.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->hmr2==0.0.0) (4.13.5)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown->hmr2==0.0.0) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->hmr2==0.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->hmr2==0.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->hmr2==0.0.0) (2025.3)\n",
            "Collecting freetype-py (from pyrender->hmr2==0.0.0)\n",
            "  Downloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from pyrender->hmr2==0.0.0) (2.37.2)\n",
            "Collecting pyglet>=1.4.10 (from pyrender->hmr2==0.0.0)\n",
            "  Downloading pyglet-2.1.12-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting PyOpenGL==3.1.0 (from pyrender->hmr2==0.0.0)\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trimesh (from pyrender->hmr2==0.0.0)\n",
            "  Downloading trimesh-4.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch-lightning->hmr2==0.0.0)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->hmr2==0.0.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->hmr2==0.0.0) (2026.1.14)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->hmr2==0.0.0) (0.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->hmr2==0.0.0) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->hmr2==0.0.0) (0.7.0)\n",
            "Collecting braceexpand (from webdataset->hmr2==0.0.0)\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (3.13.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (4.9.3)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->hmr2==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->hmr2==0.0.0) (2.8.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (8.3.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=1.0.0 (from black->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading pathspec-1.0.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (4.5.1)\n",
            "Collecting pytokens>=0.3.0 (from black->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0)\n",
            "  Downloading pytokens-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->hmr2==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->hmr2==0.0.0) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (3.3.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->hmr2==0.0.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->hmr2==0.0.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->hmr2==0.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->hmr2==0.0.0) (2026.1.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->hmr2==0.0.0) (1.7.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (3.10.1)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2->hmr2==0.0.0) (3.1.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->hmr2==0.0.0) (1.22.0)\n",
            "Downloading smplx-0.1.28-py3-none-any.whl (29 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading pyglet-2.1.12-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.11.1-py3-none-any.whl (740 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m740.4/740.4 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-1.0.4-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytokens-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (269 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: chumpy, detectron2, PyOpenGL, fvcore\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.71-py3-none-any.whl size=60862 sha256=6615829a82d90c68300670c18b8ce3d29f9fd0ccf652585000fb9d2ada62d20e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vn6ziqci/wheels/91/ec/d2/ec68a489d2208c626f1d2dd3fed33cd2b4cb14d5ffe69bdf39\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp312-cp312-linux_x86_64.whl size=7085099 sha256=f5e436a0a7e379d5e71339cf4350702d0b07a5ad58380a86a9d6a29fc8637a00\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vn6ziqci/wheels/5f/ea/7d/6637bd601e707755fb5bb8b21bc80581d34095ed4824ead192\n",
            "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745193 sha256=735f294b4c2bb192cd41cc2d73a3bed44e54b61cc7404d273fe38c3c0a39f479\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d0/77/e69597cdbcb72ea27345036f549a737909bcf17c39789472ce\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=19d4aed3ee08b682c8d200b18059cf7f6e634fb6be963e57859fd7f87ec9a3ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "Successfully built chumpy detectron2 PyOpenGL fvcore\n",
            "Installing collected packages: PyOpenGL, braceexpand, yacs, webdataset, trimesh, pytokens, pyglet, portalocker, pathspec, mypy-extensions, lightning-utilities, freetype-py, pyrender, iopath, hydra-core, chumpy, black, fvcore, torchmetrics, smplx, detectron2, pytorch-lightning, hmr2\n",
            "  Attempting uninstall: PyOpenGL\n",
            "    Found existing installation: PyOpenGL 3.1.10\n",
            "    Uninstalling PyOpenGL-3.1.10:\n",
            "      Successfully uninstalled PyOpenGL-3.1.10\n",
            "  Running setup.py develop for hmr2\n",
            "Successfully installed PyOpenGL-3.1.0 black-26.1.0 braceexpand-0.1.7 chumpy-0.71 detectron2-0.6 freetype-py-2.5.1 fvcore-0.1.5.post20221221 hmr2-0.0.0 hydra-core-1.3.2 iopath-0.1.9 lightning-utilities-0.15.2 mypy-extensions-1.1.0 pathspec-1.0.4 portalocker-3.2.0 pyglet-2.1.12 pyrender-0.1.45 pytokens-0.4.1 pytorch-lightning-2.6.1 smplx-0.1.28 torchmetrics-1.8.2 trimesh-4.11.1 webdataset-1.0.2 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install -e .[all]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBCaoIKXS_9s",
        "outputId": "16048e9d-c744-468e-808e-553bb7756168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/4D-Humans\n",
            "--2026-01-31 11:08:00--  https://github.com/classner/up/raw/821a390fbf87a522fb327fc46736eda0326e2a06/models/3D/basicModel_neutral_lbs_10_207_0_v1.0.0.pkl\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/classner/up/821a390fbf87a522fb327fc46736eda0326e2a06/models/3D/basicModel_neutral_lbs_10_207_0_v1.0.0.pkl [following]\n",
            "--2026-01-31 11:08:01--  https://raw.githubusercontent.com/classner/up/821a390fbf87a522fb327fc46736eda0326e2a06/models/3D/basicModel_neutral_lbs_10_207_0_v1.0.0.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39001280 (37M) [application/octet-stream]\n",
            "Saving to: ‘basicModel_neutral_lbs_10_207_0_v1.0.0.pkl’\n",
            "\n",
            "basicModel_neutral_ 100%[===================>]  37.19M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2026-01-31 11:08:01 (316 MB/s) - ‘basicModel_neutral_lbs_10_207_0_v1.0.0.pkl’ saved [39001280/39001280]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content/4D-Humans\n",
        "!wget https://github.com/classner/up/raw/821a390fbf87a522fb327fc46736eda0326e2a06/models/3D/basicModel_neutral_lbs_10_207_0_v1.0.0.pkl\n",
        "!mkdir data/\n",
        "!cp basicModel_neutral_lbs_10_207_0_v1.0.0.pkl ./data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_OgZoP9GsfF",
        "outputId": "ddf1db96-99c0-49b9-ed68-5d32b59b593f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-31 11:08:01--  https://people.eecs.berkeley.edu/~kanazawa/cachedir/hmr/models.tar.gz\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 385846404 (368M) [application/x-gzip]\n",
            "Saving to: ‘models.tar.gz’\n",
            "\n",
            "models.tar.gz       100%[===================>] 367.97M   104MB/s    in 3.6s    \n",
            "\n",
            "2026-01-31 11:08:05 (104 MB/s) - ‘models.tar.gz’ saved [385846404/385846404]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://people.eecs.berkeley.edu/~kanazawa/cachedir/hmr/models.tar.gz && tar -xf models.tar.gz\n",
        "\n",
        "# rename the models.tar.gz to hmr2_data.tar.gz\n",
        "!mv models.tar.gz hmr2_data.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ4QpSx8GtSR",
        "outputId": "d350ca46-a98d-403a-e06d-cd012b2cae99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-31 11:08:14--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/logs/train/multiruns/hmr2/0/model_config.yaml\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.123, 3.167.192.6, 3.167.192.19, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /api/resolve-cache/models/camenduru/4D-Humans/d4c3d4b809ba4ce1a780b91d81b151225f48b0d9/HMR2%2Flogs%2Ftrain%2Fmultiruns%2Fhmr2%2F0%2Fmodel_config.yaml?%2Fcamenduru%2F4D-Humans%2Fresolve%2Fmain%2FHMR2%2Flogs%2Ftrain%2Fmultiruns%2Fhmr2%2F0%2Fmodel_config.yaml=&etag=%22a8db0feaf3e4935d5964aa28d2bbc3659c96bf3d%22 [following]\n",
            "--2026-01-31 11:08:14--  https://huggingface.co/api/resolve-cache/models/camenduru/4D-Humans/d4c3d4b809ba4ce1a780b91d81b151225f48b0d9/HMR2%2Flogs%2Ftrain%2Fmultiruns%2Fhmr2%2F0%2Fmodel_config.yaml?%2Fcamenduru%2F4D-Humans%2Fresolve%2Fmain%2FHMR2%2Flogs%2Ftrain%2Fmultiruns%2Fhmr2%2F0%2Fmodel_config.yaml=&etag=%22a8db0feaf3e4935d5964aa28d2bbc3659c96bf3d%22\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3083 (3.0K) [text/plain]\n",
            "Saving to: ‘/content/4D-Humans/logs/train/multiruns/hmr2/0/model_config.yaml’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/4D-Humans/ 100%[===================>]   3.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2026-01-31 11:08:14 (1.63 GB/s) - ‘/content/4D-Humans/logs/train/multiruns/hmr2/0/model_config.yaml’ saved [3083/3083]\n",
            "\n",
            "--2026-01-31 11:08:14--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/logs/train/multiruns/hmr2/0/checkpoints/epoch%3D35-step%3D1000000.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.123, 3.167.192.6, 3.167.192.4, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/e47b4181bd3f618e356534e8877150b8c7083cefef06bf0e6f3e4b4790d4f03c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27epoch%25253D35-step%25253D1000000.ckpt%3B+filename%3D%22epoch%253D35-step%253D1000000.ckpt%22%3B&Expires=1769861294&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMjk0fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyL2U0N2I0MTgxYmQzZjYxOGUzNTY1MzRlODg3NzE1MGI4YzcwODNjZWZlZjA2YmYwZTZmM2U0YjQ3OTBkNGYwM2NcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=dtT9uV%7Ee-4UtKIZZzOBFUo9im%7EqX%7EC%7EPuPIz8b1%7E%7EWyiVL0EtlGzuHa68bccWd36kPIpvmoDbCQ5X9bRR2vaqFmady7TwMR3v9aG9mwGwrtROW3vZGXUa8eeIog3wiXg29BxMI1KDFAVcbZAFl9Tqobl6t1YzfOhmh4smUUUfBWBcrxhFHGiS6efUUfCKU3hIHXu1X197q5ukRZ8GoRTVAQxIs5NA-c9jSjmXXOu2qvkmLmT9NEc2XcJMwAsjFway8D%7E9v5xcN6nKmhrSU5zAi62EH0YNCqVhFZdXHX1r0ulR4myP02WqfLk5cRaWSegFJNZephD%7E2gsoT6q%7EUrPYg__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-31 11:08:14--  https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/e47b4181bd3f618e356534e8877150b8c7083cefef06bf0e6f3e4b4790d4f03c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27epoch%25253D35-step%25253D1000000.ckpt%3B+filename%3D%22epoch%253D35-step%253D1000000.ckpt%22%3B&Expires=1769861294&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMjk0fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyL2U0N2I0MTgxYmQzZjYxOGUzNTY1MzRlODg3NzE1MGI4YzcwODNjZWZlZjA2YmYwZTZmM2U0YjQ3OTBkNGYwM2NcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=dtT9uV%7Ee-4UtKIZZzOBFUo9im%7EqX%7EC%7EPuPIz8b1%7E%7EWyiVL0EtlGzuHa68bccWd36kPIpvmoDbCQ5X9bRR2vaqFmady7TwMR3v9aG9mwGwrtROW3vZGXUa8eeIog3wiXg29BxMI1KDFAVcbZAFl9Tqobl6t1YzfOhmh4smUUUfBWBcrxhFHGiS6efUUfCKU3hIHXu1X197q5ukRZ8GoRTVAQxIs5NA-c9jSjmXXOu2qvkmLmT9NEc2XcJMwAsjFway8D%7E9v5xcN6nKmhrSU5zAi62EH0YNCqVhFZdXHX1r0ulR4myP02WqfLk5cRaWSegFJNZephD%7E2gsoT6q%7EUrPYg__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2709521501 (2.5G) [application/octet-stream]\n",
            "Saving to: ‘/content/4D-Humans/logs/train/multiruns/hmr2/0/checkpoints/epoch=35-step=1000000.ckpt’\n",
            "\n",
            "/content/4D-Humans/ 100%[===================>]   2.52G   144MB/s    in 33s     \n",
            "\n",
            "2026-01-31 11:08:48 (77.6 MB/s) - ‘/content/4D-Humans/logs/train/multiruns/hmr2/0/checkpoints/epoch=35-step=1000000.ckpt’ saved [2709521501/2709521501]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Create the expected directory structure\n",
        "!mkdir -p /content/4D-Humans/logs/train/multiruns/hmr2/0/checkpoints\n",
        "\n",
        "# 2. Download the config file and place it two levels up from the checkpoint\n",
        "!wget -O /content/4D-Humans/logs/train/multiruns/hmr2/0/model_config.yaml https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/logs/train/multiruns/hmr2/0/model_config.yaml\n",
        "\n",
        "# 3. Download the model checkpoint into the checkpoints folder\n",
        "!wget -O /content/4D-Humans/logs/train/multiruns/hmr2/0/checkpoints/epoch=35-step=1000000.ckpt https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/logs/train/multiruns/hmr2/0/checkpoints/epoch%3D35-step%3D1000000.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY6VrY1pHOop",
        "outputId": "e13ee96f-44f1-422c-c494-6d3b74ae9be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-31 11:08:48--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl/SMPL_NEUTRAL.pkl\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.6, 3.167.192.4, 3.167.192.19, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/053f2928db45aa46b69aaf6a2d706d9c8b7a7fcdad59466b0f80dca92af9696d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_NEUTRAL.pkl%3B+filename%3D%22SMPL_NEUTRAL.pkl%22%3B&Expires=1769861328&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzI4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyLzA1M2YyOTI4ZGI0NWFhNDZiNjlhYWY2YTJkNzA2ZDljOGI3YTdmY2RhZDU5NDY2YjBmODBkY2E5MmFmOTY5NmRcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=X4IIP5nBLVJJ3KZF%7EPrZKNMFKwzARPyWS11%7ElpfNI71SiUwmnPVVq4KFO3BmsJnUmGSae6IaI0lwe5Onu1gRX1kVBk207oehMEP4B2a22socO8XhIJOBSk-jSEHxYsxkIY%7Eb5upYjVA9xL7lynhixoTcABWEmmb-b7MP9SANhq7Bsm676HhfI9HAVboyvCWGx9niB0qGLCTYqi05AR0wY3pRZBe%7EFglGEoYMbDvunyrOLoSBPvKBiMcP3w%7EdYRE902aeVLFol9ZCSlaZmRPO-sJfLzbv9H27ymYW8fuXScciSmNp%7E9lV72f4JxGU75SjjDu1ermz7qUkgvTyVROo6w__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-31 11:08:48--  https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/053f2928db45aa46b69aaf6a2d706d9c8b7a7fcdad59466b0f80dca92af9696d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_NEUTRAL.pkl%3B+filename%3D%22SMPL_NEUTRAL.pkl%22%3B&Expires=1769861328&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzI4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyLzA1M2YyOTI4ZGI0NWFhNDZiNjlhYWY2YTJkNzA2ZDljOGI3YTdmY2RhZDU5NDY2YjBmODBkY2E5MmFmOTY5NmRcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=X4IIP5nBLVJJ3KZF%7EPrZKNMFKwzARPyWS11%7ElpfNI71SiUwmnPVVq4KFO3BmsJnUmGSae6IaI0lwe5Onu1gRX1kVBk207oehMEP4B2a22socO8XhIJOBSk-jSEHxYsxkIY%7Eb5upYjVA9xL7lynhixoTcABWEmmb-b7MP9SANhq7Bsm676HhfI9HAVboyvCWGx9niB0qGLCTYqi05AR0wY3pRZBe%7EFglGEoYMbDvunyrOLoSBPvKBiMcP3w%7EdYRE902aeVLFol9ZCSlaZmRPO-sJfLzbv9H27ymYW8fuXScciSmNp%7E9lV72f4JxGU75SjjDu1ermz7qUkgvTyVROo6w__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109007243 (104M) [application/octet-stream]\n",
            "Saving to: ‘/root/.cache/4DHumans/data/smpl/SMPL_NEUTRAL.pkl’\n",
            "\n",
            "/root/.cache/4DHuma 100%[===================>] 103.96M  60.4MB/s    in 1.7s    \n",
            "\n",
            "2026-01-31 11:08:50 (60.4 MB/s) - ‘/root/.cache/4DHumans/data/smpl/SMPL_NEUTRAL.pkl’ saved [109007243/109007243]\n",
            "\n",
            "--2026-01-31 11:08:50--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl/SMPL_MALE.pkl\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.6, 3.167.192.4, 3.167.192.19, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/053f2928db45aa46b69aaf6a2d706d9c8b7a7fcdad59466b0f80dca92af9696d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_MALE.pkl%3B+filename%3D%22SMPL_MALE.pkl%22%3B&Expires=1769861330&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzMwfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyLzA1M2YyOTI4ZGI0NWFhNDZiNjlhYWY2YTJkNzA2ZDljOGI3YTdmY2RhZDU5NDY2YjBmODBkY2E5MmFmOTY5NmRcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=KWrHLQKNQqc8wCJJhuJWbmnoU9pSQ9RJCrDF4i71Nt4bAU51gKu5lGWBhVzVEx-Y3ukqJZlG%7EK9fccqDpWoSP-IHJwtJO6bVWPcFkxD98p1p8iuFSeyWvV2cURk%7EylnSoIIRna5qWulX4hVWgQPGAiq%7Ep%7Euj7pk3ZG%7ELd8H5%7ErnltJ2QeOeAZJ%7ENNfxIxnCHRiItb7FJB4GHdv5sJvhEnpAH7Y9Wv6KtzhO7TI5gslf3Sxj5CGpF0I1NKg-jq0kB%7EKPPG4ITSJp73Hxsf%7ENaZBNM931JZVkM-Wm8uuL-u0mOqoABIwnaw%7EuSDyAdvknmlzOs1xekbD15myedqTAuCw__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-31 11:08:50--  https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/053f2928db45aa46b69aaf6a2d706d9c8b7a7fcdad59466b0f80dca92af9696d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_MALE.pkl%3B+filename%3D%22SMPL_MALE.pkl%22%3B&Expires=1769861330&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzMwfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyLzA1M2YyOTI4ZGI0NWFhNDZiNjlhYWY2YTJkNzA2ZDljOGI3YTdmY2RhZDU5NDY2YjBmODBkY2E5MmFmOTY5NmRcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=KWrHLQKNQqc8wCJJhuJWbmnoU9pSQ9RJCrDF4i71Nt4bAU51gKu5lGWBhVzVEx-Y3ukqJZlG%7EK9fccqDpWoSP-IHJwtJO6bVWPcFkxD98p1p8iuFSeyWvV2cURk%7EylnSoIIRna5qWulX4hVWgQPGAiq%7Ep%7Euj7pk3ZG%7ELd8H5%7ErnltJ2QeOeAZJ%7ENNfxIxnCHRiItb7FJB4GHdv5sJvhEnpAH7Y9Wv6KtzhO7TI5gslf3Sxj5CGpF0I1NKg-jq0kB%7EKPPG4ITSJp73Hxsf%7ENaZBNM931JZVkM-Wm8uuL-u0mOqoABIwnaw%7EuSDyAdvknmlzOs1xekbD15myedqTAuCw__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109007243 (104M) [application/octet-stream]\n",
            "Saving to: ‘/root/.cache/4DHumans/data/smpl/SMPL_MALE.pkl’\n",
            "\n",
            "/root/.cache/4DHuma 100%[===================>] 103.96M  90.7MB/s    in 1.1s    \n",
            "\n",
            "2026-01-31 11:08:51 (90.7 MB/s) - ‘/root/.cache/4DHumans/data/smpl/SMPL_MALE.pkl’ saved [109007243/109007243]\n",
            "\n",
            "--2026-01-31 11:08:51--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl/SMPL_FEMALE.pkl\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.6, 3.167.192.4, 3.167.192.19, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/053f2928db45aa46b69aaf6a2d706d9c8b7a7fcdad59466b0f80dca92af9696d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_FEMALE.pkl%3B+filename%3D%22SMPL_FEMALE.pkl%22%3B&Expires=1769861331&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzMxfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyLzA1M2YyOTI4ZGI0NWFhNDZiNjlhYWY2YTJkNzA2ZDljOGI3YTdmY2RhZDU5NDY2YjBmODBkY2E5MmFmOTY5NmRcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=kYAVxO4lR86RixHAnk-fZuq8t-t3fR4XBNuJLY6P0TMoNpnLnqQNNTbO4M3%7E-KpVZSdLOV5QWTPuP59VZRfaRlLoVzoV9iupecVCJzRuC-Pin3VgNpeRIN1VLahl01olo1GcBmN%7EsQ6F97g%7EZy7T9-TljPZeA8wLK4ggKBFfkn362d6YSCCGtLg8FSuzYR0B-0O0MQ9%7E85M5KfxaQJ5lERn2vYpbyYxWLmrD3r-p4jjKofTw-ZumGfmSqD%7EfbD-NAxJQJ4o%7EaMr3aosrAPyQ%7E0DuZCO6SeIskXyrcXcKCqwJZMQvjabL0cuGabb2P9gosSV3GRZRkfPRMonts2BWkw__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-31 11:08:51--  https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/053f2928db45aa46b69aaf6a2d706d9c8b7a7fcdad59466b0f80dca92af9696d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_FEMALE.pkl%3B+filename%3D%22SMPL_FEMALE.pkl%22%3B&Expires=1769861331&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzMxfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyLzA1M2YyOTI4ZGI0NWFhNDZiNjlhYWY2YTJkNzA2ZDljOGI3YTdmY2RhZDU5NDY2YjBmODBkY2E5MmFmOTY5NmRcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=kYAVxO4lR86RixHAnk-fZuq8t-t3fR4XBNuJLY6P0TMoNpnLnqQNNTbO4M3%7E-KpVZSdLOV5QWTPuP59VZRfaRlLoVzoV9iupecVCJzRuC-Pin3VgNpeRIN1VLahl01olo1GcBmN%7EsQ6F97g%7EZy7T9-TljPZeA8wLK4ggKBFfkn362d6YSCCGtLg8FSuzYR0B-0O0MQ9%7E85M5KfxaQJ5lERn2vYpbyYxWLmrD3r-p4jjKofTw-ZumGfmSqD%7EfbD-NAxJQJ4o%7EaMr3aosrAPyQ%7E0DuZCO6SeIskXyrcXcKCqwJZMQvjabL0cuGabb2P9gosSV3GRZRkfPRMonts2BWkw__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109007243 (104M) [application/octet-stream]\n",
            "Saving to: ‘/root/.cache/4DHumans/data/smpl/SMPL_FEMALE.pkl’\n",
            "\n",
            "/root/.cache/4DHuma 100%[===================>] 103.96M   139MB/s    in 0.7s    \n",
            "\n",
            "2026-01-31 11:08:52 (139 MB/s) - ‘/root/.cache/4DHumans/data/smpl/SMPL_FEMALE.pkl’ saved [109007243/109007243]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Create the hidden cache directory for 4D-Humans\n",
        "!mkdir -p /root/.cache/4DHumans/data/smpl/\n",
        "\n",
        "# 2. Download the SMPL Neutral model\n",
        "# (Using a public mirror since the official one requires a manual login)\n",
        "!wget -O /root/.cache/4DHumans/data/smpl/SMPL_NEUTRAL.pkl https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl/SMPL_NEUTRAL.pkl\n",
        "\n",
        "# 3. (Optional) Download Male/Female models if you plan to use gender-specific tracking\n",
        "!wget -O /root/.cache/4DHumans/data/smpl/SMPL_MALE.pkl https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl/SMPL_MALE.pkl\n",
        "!wget -O /root/.cache/4DHumans/data/smpl/SMPL_FEMALE.pkl https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl/SMPL_FEMALE.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGQDbX0EH2Nu",
        "outputId": "aebd34f4-ddf7-4bb4-9998-73120d072443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-31 11:08:59--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl_mean_params.npz\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.6, 3.167.192.4, 3.167.192.19, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/ab0085fbf56892e32396d6e3eca9d32f663a9e2f511ae81ae0616f92ef3c7a08?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27smpl_mean_params.npz%3B+filename%3D%22smpl_mean_params.npz%22%3B&Expires=1769861339&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzM5fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyL2FiMDA4NWZiZjU2ODkyZTMyMzk2ZDZlM2VjYTlkMzJmNjYzYTllMmY1MTFhZTgxYWUwNjE2ZjkyZWYzYzdhMDhcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=RmHqtL8PEznXLuc4c08XayzSCqWRKCb5HbnZ3TijlGfiFo6CCvzyNRKpVTPAzNSv6OijSuRz%7EPmg4OUEZjBXHhqRhLheGSXX-VxmenlkUWyPPe97%7EhaKcD5kpE66by7uPNCZOraeCzd3XbrIxx1EoR-QoXl4NSQWUIYhcFl5d3dQ7cUwHwU7-By8Bf3Ol2wCaKtGX-%7EhnxHDzYN7Hy519hCLto1KfpW05%7EqOZWKnj-zVgB36E3XpD5twseZ-NnKNKsF-JXhL5vk-P98Thtq4vaobHQK1BSuUvgk0ihrcGWmigfuSB3nlI7UgtvH6wfNmmoQ-L2XBKTlUBJGSzG8D8w__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-31 11:08:59--  https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/ab0085fbf56892e32396d6e3eca9d32f663a9e2f511ae81ae0616f92ef3c7a08?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27smpl_mean_params.npz%3B+filename%3D%22smpl_mean_params.npz%22%3B&Expires=1769861339&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzM5fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyL2FiMDA4NWZiZjU2ODkyZTMyMzk2ZDZlM2VjYTlkMzJmNjYzYTllMmY1MTFhZTgxYWUwNjE2ZjkyZWYzYzdhMDhcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=RmHqtL8PEznXLuc4c08XayzSCqWRKCb5HbnZ3TijlGfiFo6CCvzyNRKpVTPAzNSv6OijSuRz%7EPmg4OUEZjBXHhqRhLheGSXX-VxmenlkUWyPPe97%7EhaKcD5kpE66by7uPNCZOraeCzd3XbrIxx1EoR-QoXl4NSQWUIYhcFl5d3dQ7cUwHwU7-By8Bf3Ol2wCaKtGX-%7EhnxHDzYN7Hy519hCLto1KfpW05%7EqOZWKnj-zVgB36E3XpD5twseZ-NnKNKsF-JXhL5vk-P98Thtq4vaobHQK1BSuUvgk0ihrcGWmigfuSB3nlI7UgtvH6wfNmmoQ-L2XBKTlUBJGSzG8D8w__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1310 (1.3K) [application/octet-stream]\n",
            "Saving to: ‘/root/.cache/4DHumans/data/smpl_mean_params.npz’\n",
            "\n",
            "/root/.cache/4DHuma 100%[===================>]   1.28K  4.45KB/s    in 0.3s    \n",
            "\n",
            "2026-01-31 11:08:59 (4.45 KB/s) - ‘/root/.cache/4DHumans/data/smpl_mean_params.npz’ saved [1310/1310]\n",
            "\n",
            "--2026-01-31 11:09:00--  https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/SMPL_to_J19.pkl\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.192.6, 3.167.192.4, 3.167.192.19, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.192.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/f12cd19a372c1cf0513abca66d4f2279e799f7f6bce17c71070af4918ca243f8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_to_J19.pkl%3B+filename%3D%22SMPL_to_J19.pkl%22%3B&Expires=1769861340&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzQwfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyL2YxMmNkMTlhMzcyYzFjZjA1MTNhYmNhNjZkNGYyMjc5ZTc5OWY3ZjZiY2UxN2M3MTA3MGFmNDkxOGNhMjQzZjhcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=KKhIiQNg052sUAzz1VZJL-Vg-PwKl3C6hYwUjxmjgTQV-woYXIQEdmimulhuQUIeCBxzwJKc-H10FwN2fZQ8XDbEWTgme3qoDx-jePZR57xHlBWggSG1pOpr0Ng4%7E1W-RT0IAydo8LaLe1pKeJnH2-I6hjOe9FCWropOICBEQD09HEFLCO1fUQZradbraEN9LIkPJolcqf8VK5UDDN78%7EZmiyFBUuN6ejQPt75uT7NE6-khwyxuf-8Si2%7Eu6CbhmPDoVPicvSVlYUF3nV%7ERMDejgVO6469S-VPmxwHl%7E2qPRPtaBidnPG2M-vGUtKi80HFNuIQq8uERytJHKHnpA6g__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-31 11:09:00--  https://us.gcp.cdn.hf.co/xet-bridge-us/6478247004aa03da2acc1872/f12cd19a372c1cf0513abca66d4f2279e799f7f6bce17c71070af4918ca243f8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27SMPL_to_J19.pkl%3B+filename%3D%22SMPL_to_J19.pkl%22%3B&Expires=1769861340&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY5ODYxMzQwfX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ3ODI0NzAwNGFhMDNkYTJhY2MxODcyL2YxMmNkMTlhMzcyYzFjZjA1MTNhYmNhNjZkNGYyMjc5ZTc5OWY3ZjZiY2UxN2M3MTA3MGFmNDkxOGNhMjQzZjhcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=KKhIiQNg052sUAzz1VZJL-Vg-PwKl3C6hYwUjxmjgTQV-woYXIQEdmimulhuQUIeCBxzwJKc-H10FwN2fZQ8XDbEWTgme3qoDx-jePZR57xHlBWggSG1pOpr0Ng4%7E1W-RT0IAydo8LaLe1pKeJnH2-I6hjOe9FCWropOICBEQD09HEFLCO1fUQZradbraEN9LIkPJolcqf8VK5UDDN78%7EZmiyFBUuN6ejQPt75uT7NE6-khwyxuf-8Si2%7Eu6CbhmPDoVPicvSVlYUF3nV%7ERMDejgVO6469S-VPmxwHl%7E2qPRPtaBidnPG2M-vGUtKi80HFNuIQq8uERytJHKHnpA6g__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1047441 (1023K) [application/octet-stream]\n",
            "Saving to: ‘/root/.cache/4DHumans/data/SMPL_to_J19.pkl’\n",
            "\n",
            "/root/.cache/4DHuma 100%[===================>]   1023K  5.25MB/s    in 0.2s    \n",
            "\n",
            "2026-01-31 11:09:00 (5.25 MB/s) - ‘/root/.cache/4DHumans/data/SMPL_to_J19.pkl’ saved [1047441/1047441]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Ensure the cache directory exists\n",
        "!mkdir -p /root/.cache/4DHumans/data/\n",
        "\n",
        "# 2. Download the Mean Parameters (Crucial for the SMPL Head)\n",
        "!wget -O /root/.cache/4DHumans/data/smpl_mean_params.npz https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/smpl_mean_params.npz\n",
        "\n",
        "# 3. Download the Joint Mapping (Usually needed immediately after the mean params)\n",
        "!wget -O /root/.cache/4DHumans/data/SMPL_to_J19.pkl https://huggingface.co/camenduru/4D-Humans/resolve/main/HMR2/data/SMPL_to_J19.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TtHr2piAHj4W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from omegaconf.dictconfig import DictConfig\n",
        "os.environ[\"TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD\"] = \"1\"\n",
        "torch.serialization.add_safe_globals([DictConfig])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca_EjQXGGzua",
        "outputId": "f5b84896-8dfe-439b-e222-8a553d268a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/4D-Humans\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading file: models.tar.gz\n",
            "Downloading remote file https://people.eecs.berkeley.edu/~kanazawa/cachedir/hmr/models.tar.gz to /root/.cache/4DHumans/models.tar.gz\n",
            "  [============================================================] 100.0% of 368.0MB file  \n",
            "Extracting file: models.tar.gz\n",
            "models/\n",
            "models/model.ckpt-667589.meta\n",
            "models/neutral_smpl_with_cocoplus_reg.pkl\n",
            "models/model.ckpt-667589.index\n",
            "models/model.ckpt-667589.data-00000-of-00001\n",
            "/usr/local/lib/python3.12/dist-packages/lightning_fabric/utilities/cloud_io.py:73: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.8.1 to v2.6.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint logs/train/multiruns/hmr2/0/checkpoints/epoch=35-step=1000000.ckpt`\n",
            "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
            "model_final_f05665.pkl: 2.77GB [00:16, 168MB/s]                \n",
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "W0131 11:12:12.023000 3544 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
            "downsampling_factor=np.float32(11.122095)\n",
            "/content/4D-Humans/hmr2/utils/geometry.py:61: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
            "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
            "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /pytorch/aten/src/ATen/native/Cross.cpp:63.)\n",
            "  b3 = torch.cross(b1, b2)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "[ WARN:0@101.993] global loadsave.cpp:1089 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "92.18128705024719\n",
            "downsampling_factor=np.float32(4.9224873)\n",
            "downsampling_factor=np.float32(0.77441216)\n",
            "downsampling_factor=np.float32(1.4262086)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "98.09378433227539\n",
            "downsampling_factor=np.float32(4.2399516)\n",
            "downsampling_factor=np.float32(1.5506306)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "103.04357695579529\n",
            "downsampling_factor=np.float32(0.921582)\n",
            "downsampling_factor=np.float32(0.39511338)\n",
            "downsampling_factor=np.float32(0.36077598)\n",
            "downsampling_factor=np.float32(0.45085016)\n",
            "downsampling_factor=np.float32(0.37092802)\n",
            "downsampling_factor=np.float32(0.29577637)\n",
            "downsampling_factor=np.float32(0.17338602)\n",
            "downsampling_factor=np.float32(0.22018613)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.32782617)\n",
            "downsampling_factor=np.float32(0.18823878)\n",
            "downsampling_factor=np.float32(0.4933631)\n",
            "downsampling_factor=np.float32(0.36138567)\n",
            "downsampling_factor=np.float32(0.34924558)\n",
            "downsampling_factor=np.float32(0.23151053)\n",
            "downsampling_factor=np.float32(0.2612594)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "120.21926808357239\n",
            "downsampling_factor=np.float32(3.6690295)\n",
            "downsampling_factor=np.float32(1.2423708)\n",
            "downsampling_factor=np.float32(1.3481808)\n",
            "downsampling_factor=np.float32(0.8818105)\n",
            "downsampling_factor=np.float32(0.53354955)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "128.48366594314575\n",
            "downsampling_factor=np.float32(0.83730036)\n",
            "downsampling_factor=np.float32(0.37025028)\n",
            "downsampling_factor=np.float32(0.38406432)\n",
            "downsampling_factor=np.float32(0.381213)\n",
            "downsampling_factor=np.float32(0.4650917)\n",
            "downsampling_factor=np.float32(0.32054487)\n",
            "downsampling_factor=np.float32(0.23392391)\n",
            "downsampling_factor=np.float32(0.21308093)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17120107)\n",
            "downsampling_factor=np.float32(0.32546106)\n",
            "downsampling_factor=np.float32(0.49911553)\n",
            "downsampling_factor=np.float32(0.28289986)\n",
            "downsampling_factor=np.float32(0.33556128)\n",
            "downsampling_factor=np.float32(0.22742496)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "144.7536826133728\n",
            "downsampling_factor=np.float32(2.816195)\n",
            "downsampling_factor=np.float32(0.5080509)\n",
            "downsampling_factor=np.float32(0.5680873)\n",
            "downsampling_factor=np.float32(0.5956033)\n",
            "downsampling_factor=np.float32(0.35437456)\n",
            "downsampling_factor=np.float32(0.44118595)\n",
            "downsampling_factor=np.float32(0.33857378)\n",
            "downsampling_factor=np.float32(0.53467494)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.5704797)\n",
            "downsampling_factor=np.float32(0.56934947)\n",
            "downsampling_factor=np.float32(0.37835822)\n",
            "downsampling_factor=np.float32(0.4830993)\n",
            "downsampling_factor=np.float32(0.5103076)\n",
            "downsampling_factor=np.float32(0.33972454)\n",
            "downsampling_factor=np.float32(0.50238675)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "162.7249894142151\n",
            "downsampling_factor=np.float32(0.80632067)\n",
            "downsampling_factor=np.float32(0.4070995)\n",
            "downsampling_factor=np.float32(0.38561136)\n",
            "downsampling_factor=np.float32(0.37837702)\n",
            "downsampling_factor=np.float32(0.28744584)\n",
            "downsampling_factor=np.float32(0.4699552)\n",
            "downsampling_factor=np.float32(0.23239847)\n",
            "downsampling_factor=np.float32(0.17032611)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21071844)\n",
            "downsampling_factor=np.float32(0.34104857)\n",
            "downsampling_factor=np.float32(0.28183818)\n",
            "downsampling_factor=np.float32(0.49437243)\n",
            "downsampling_factor=np.float32(0.3312964)\n",
            "downsampling_factor=np.float32(0.22698033)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "179.00816941261292\n",
            "downsampling_factor=np.float32(0.9179389)\n",
            "downsampling_factor=np.float32(0.4343354)\n",
            "downsampling_factor=np.float32(0.382763)\n",
            "downsampling_factor=np.float32(0.37875587)\n",
            "downsampling_factor=np.float32(0.46633592)\n",
            "downsampling_factor=np.float32(0.31671286)\n",
            "downsampling_factor=np.float32(0.2376426)\n",
            "downsampling_factor=np.float32(0.21282049)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17176326)\n",
            "downsampling_factor=np.float32(0.32419074)\n",
            "downsampling_factor=np.float32(0.2902266)\n",
            "downsampling_factor=np.float32(0.50073105)\n",
            "downsampling_factor=np.float32(0.33313954)\n",
            "downsampling_factor=np.float32(0.22907162)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "195.49583268165588\n",
            "downsampling_factor=np.float32(0.77373195)\n",
            "downsampling_factor=np.float32(0.4117597)\n",
            "downsampling_factor=np.float32(0.3653558)\n",
            "downsampling_factor=np.float32(0.44966155)\n",
            "downsampling_factor=np.float32(0.37161148)\n",
            "downsampling_factor=np.float32(0.29365364)\n",
            "downsampling_factor=np.float32(0.32969233)\n",
            "downsampling_factor=np.float32(0.17152119)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21905087)\n",
            "downsampling_factor=np.float32(0.19536881)\n",
            "downsampling_factor=np.float32(0.48739874)\n",
            "downsampling_factor=np.float32(0.24164064)\n",
            "downsampling_factor=np.float32(0.3669277)\n",
            "downsampling_factor=np.float32(0.3332408)\n",
            "downsampling_factor=np.float32(0.25645036)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "212.81414008140564\n",
            "downsampling_factor=np.float32(1.4439768)\n",
            "downsampling_factor=np.float32(0.44472694)\n",
            "downsampling_factor=np.float32(0.30402282)\n",
            "downsampling_factor=np.float32(0.38661906)\n",
            "downsampling_factor=np.float32(0.37757534)\n",
            "downsampling_factor=np.float32(0.45743263)\n",
            "downsampling_factor=np.float32(0.18860395)\n",
            "downsampling_factor=np.float32(0.34576613)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.19070722)\n",
            "downsampling_factor=np.float32(0.23430094)\n",
            "downsampling_factor=np.float32(0.49435908)\n",
            "downsampling_factor=np.float32(0.3380735)\n",
            "downsampling_factor=np.float32(0.37259334)\n",
            "downsampling_factor=np.float32(0.33028388)\n",
            "downsampling_factor=np.float32(0.2595906)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "230.14298295974731\n",
            "downsampling_factor=np.float32(0.7546909)\n",
            "downsampling_factor=np.float32(0.48633724)\n",
            "downsampling_factor=np.float32(0.38493398)\n",
            "downsampling_factor=np.float32(0.38648763)\n",
            "downsampling_factor=np.float32(0.46675688)\n",
            "downsampling_factor=np.float32(0.2280153)\n",
            "downsampling_factor=np.float32(0.21477132)\n",
            "downsampling_factor=np.float32(0.17217273)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.5019924)\n",
            "downsampling_factor=np.float32(0.2562848)\n",
            "downsampling_factor=np.float32(0.45261082)\n",
            "downsampling_factor=np.float32(0.34720978)\n",
            "downsampling_factor=np.float32(0.33710945)\n",
            "downsampling_factor=np.float32(0.22499394)\n",
            "downsampling_factor=np.float32(0.27416062)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "247.84415340423584\n",
            "downsampling_factor=np.float32(0.9315691)\n",
            "downsampling_factor=np.float32(0.38074684)\n",
            "downsampling_factor=np.float32(0.36080223)\n",
            "downsampling_factor=np.float32(0.45007005)\n",
            "downsampling_factor=np.float32(0.36982992)\n",
            "downsampling_factor=np.float32(0.30434844)\n",
            "downsampling_factor=np.float32(0.17295337)\n",
            "downsampling_factor=np.float32(0.31088382)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21980731)\n",
            "downsampling_factor=np.float32(0.18699987)\n",
            "downsampling_factor=np.float32(0.48477218)\n",
            "downsampling_factor=np.float32(0.3659983)\n",
            "downsampling_factor=np.float32(0.34889936)\n",
            "downsampling_factor=np.float32(0.263144)\n",
            "downsampling_factor=np.float32(0.23830098)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "265.26627254486084\n",
            "downsampling_factor=np.float32(0.8628142)\n",
            "downsampling_factor=np.float32(0.38653892)\n",
            "downsampling_factor=np.float32(0.37591285)\n",
            "downsampling_factor=np.float32(0.31468058)\n",
            "downsampling_factor=np.float32(0.37666118)\n",
            "downsampling_factor=np.float32(0.44609588)\n",
            "downsampling_factor=np.float32(0.22096094)\n",
            "downsampling_factor=np.float32(0.18561268)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.2014064)\n",
            "downsampling_factor=np.float32(0.4795736)\n",
            "downsampling_factor=np.float32(0.31989765)\n",
            "downsampling_factor=np.float32(0.3323406)\n",
            "downsampling_factor=np.float32(0.48539686)\n",
            "downsampling_factor=np.float32(0.39254066)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "282.67325472831726\n",
            "downsampling_factor=np.float32(5.1953864)\n",
            "downsampling_factor=np.float32(1.8090096)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "287.84397649765015\n",
            "downsampling_factor=np.float32(0.94605035)\n",
            "downsampling_factor=np.float32(0.39636874)\n",
            "downsampling_factor=np.float32(0.38373125)\n",
            "downsampling_factor=np.float32(0.3817882)\n",
            "downsampling_factor=np.float32(0.31879315)\n",
            "downsampling_factor=np.float32(0.46544456)\n",
            "downsampling_factor=np.float32(0.23614776)\n",
            "downsampling_factor=np.float32(0.21154778)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.1708873)\n",
            "downsampling_factor=np.float32(0.3264632)\n",
            "downsampling_factor=np.float32(0.28162798)\n",
            "downsampling_factor=np.float32(0.49939224)\n",
            "downsampling_factor=np.float32(0.3349768)\n",
            "downsampling_factor=np.float32(0.22814447)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "304.84895968437195\n",
            "downsampling_factor=np.float32(0.7952597)\n",
            "downsampling_factor=np.float32(0.42824703)\n",
            "downsampling_factor=np.float32(0.38486272)\n",
            "downsampling_factor=np.float32(0.37802073)\n",
            "downsampling_factor=np.float32(0.2981165)\n",
            "downsampling_factor=np.float32(0.4694392)\n",
            "downsampling_factor=np.float32(0.23170173)\n",
            "downsampling_factor=np.float32(0.17075503)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21156581)\n",
            "downsampling_factor=np.float32(0.34497055)\n",
            "downsampling_factor=np.float32(0.49793822)\n",
            "downsampling_factor=np.float32(0.28011432)\n",
            "downsampling_factor=np.float32(0.3382353)\n",
            "downsampling_factor=np.float32(0.22725517)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "322.06579780578613\n",
            "downsampling_factor=np.float32(2.894817)\n",
            "downsampling_factor=np.float32(0.54166603)\n",
            "downsampling_factor=np.float32(0.5814743)\n",
            "downsampling_factor=np.float32(0.3819847)\n",
            "downsampling_factor=np.float32(0.58824986)\n",
            "downsampling_factor=np.float32(0.3200995)\n",
            "downsampling_factor=np.float32(0.3341433)\n",
            "downsampling_factor=np.float32(0.28017583)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.44309223)\n",
            "downsampling_factor=np.float32(0.45711374)\n",
            "downsampling_factor=np.float32(0.59246826)\n",
            "downsampling_factor=np.float32(0.5458129)\n",
            "downsampling_factor=np.float32(0.51383656)\n",
            "downsampling_factor=np.float32(0.49798393)\n",
            "downsampling_factor=np.float32(0.44366997)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "339.8966555595398\n",
            "downsampling_factor=np.float32(0.8501954)\n",
            "downsampling_factor=np.float32(0.5399452)\n",
            "downsampling_factor=np.float32(0.38290045)\n",
            "downsampling_factor=np.float32(0.37957922)\n",
            "downsampling_factor=np.float32(0.46746)\n",
            "downsampling_factor=np.float32(0.23054159)\n",
            "downsampling_factor=np.float32(0.17115831)\n",
            "downsampling_factor=np.float32(0.21402343)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.42300102)\n",
            "downsampling_factor=np.float32(0.3636023)\n",
            "downsampling_factor=np.float32(0.49979618)\n",
            "downsampling_factor=np.float32(0.33302715)\n",
            "downsampling_factor=np.float32(0.26894894)\n",
            "downsampling_factor=np.float32(0.22712922)\n",
            "downsampling_factor=np.float32(0.27273753)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "357.5863482952118\n",
            "downsampling_factor=np.float32(0.9160178)\n",
            "downsampling_factor=np.float32(0.45702094)\n",
            "downsampling_factor=np.float32(0.38139573)\n",
            "downsampling_factor=np.float32(0.36260206)\n",
            "downsampling_factor=np.float32(0.4476452)\n",
            "downsampling_factor=np.float32(0.4636487)\n",
            "downsampling_factor=np.float32(0.1698749)\n",
            "downsampling_factor=np.float32(0.27711773)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.18989594)\n",
            "downsampling_factor=np.float32(0.21654242)\n",
            "downsampling_factor=np.float32(0.47442532)\n",
            "downsampling_factor=np.float32(0.24147514)\n",
            "downsampling_factor=np.float32(0.3280758)\n",
            "downsampling_factor=np.float32(0.34622812)\n",
            "downsampling_factor=np.float32(0.2569971)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "375.4158651828766\n",
            "downsampling_factor=np.float32(4.548307)\n",
            "downsampling_factor=np.float32(1.633716)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "381.01628589630127\n",
            "downsampling_factor=np.float32(0.9020281)\n",
            "downsampling_factor=np.float32(0.4506994)\n",
            "downsampling_factor=np.float32(0.38516098)\n",
            "downsampling_factor=np.float32(0.36333176)\n",
            "downsampling_factor=np.float32(0.44928232)\n",
            "downsampling_factor=np.float32(0.46149302)\n",
            "downsampling_factor=np.float32(0.2740151)\n",
            "downsampling_factor=np.float32(0.21815324)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.19597054)\n",
            "downsampling_factor=np.float32(0.1983623)\n",
            "downsampling_factor=np.float32(0.46805456)\n",
            "downsampling_factor=np.float32(0.2507511)\n",
            "downsampling_factor=np.float32(0.25324407)\n",
            "downsampling_factor=np.float32(0.3303307)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "397.7159512042999\n",
            "downsampling_factor=np.float32(1.20423)\n",
            "downsampling_factor=np.float32(0.38703382)\n",
            "downsampling_factor=np.float32(0.37585786)\n",
            "downsampling_factor=np.float32(0.3059424)\n",
            "downsampling_factor=np.float32(0.3838425)\n",
            "downsampling_factor=np.float32(0.4562175)\n",
            "downsampling_factor=np.float32(0.19249995)\n",
            "downsampling_factor=np.float32(0.18729389)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.23547047)\n",
            "downsampling_factor=np.float32(0.34630042)\n",
            "downsampling_factor=np.float32(0.34538788)\n",
            "downsampling_factor=np.float32(0.27721086)\n",
            "downsampling_factor=np.float32(0.3290844)\n",
            "downsampling_factor=np.float32(0.48460135)\n",
            "downsampling_factor=np.float32(0.19853103)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "416.3446831703186\n",
            "downsampling_factor=np.float32(2.9240599)\n",
            "downsampling_factor=np.float32(0.54136115)\n",
            "downsampling_factor=np.float32(0.5731436)\n",
            "downsampling_factor=np.float32(0.6024431)\n",
            "downsampling_factor=np.float32(0.35954413)\n",
            "downsampling_factor=np.float32(0.41558743)\n",
            "downsampling_factor=np.float32(0.28403285)\n",
            "downsampling_factor=np.float32(0.5844701)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.42867815)\n",
            "downsampling_factor=np.float32(0.3318348)\n",
            "downsampling_factor=np.float32(0.41163048)\n",
            "downsampling_factor=np.float32(0.5174077)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "431.7790503501892\n",
            "downsampling_factor=np.float32(0.9350278)\n",
            "downsampling_factor=np.float32(0.4239582)\n",
            "downsampling_factor=np.float32(0.36319456)\n",
            "downsampling_factor=np.float32(0.45122206)\n",
            "downsampling_factor=np.float32(0.370628)\n",
            "downsampling_factor=np.float32(0.29166937)\n",
            "downsampling_factor=np.float32(0.17320783)\n",
            "downsampling_factor=np.float32(0.22107695)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.45881584)\n",
            "downsampling_factor=np.float32(0.19196351)\n",
            "downsampling_factor=np.float32(0.49435306)\n",
            "downsampling_factor=np.float32(0.336813)\n",
            "downsampling_factor=np.float32(0.3658544)\n",
            "downsampling_factor=np.float32(0.25532162)\n",
            "downsampling_factor=np.float32(0.2393276)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "450.38915514945984\n",
            "downsampling_factor=np.float32(4.431071)\n",
            "downsampling_factor=np.float32(1.4780592)\n",
            "downsampling_factor=np.float32(0.7515478)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "456.8342218399048\n",
            "downsampling_factor=np.float32(0.8520577)\n",
            "downsampling_factor=np.float32(0.38921)\n",
            "downsampling_factor=np.float32(0.37079)\n",
            "downsampling_factor=np.float32(0.4502867)\n",
            "downsampling_factor=np.float32(0.36859393)\n",
            "downsampling_factor=np.float32(0.28439632)\n",
            "downsampling_factor=np.float32(0.38025963)\n",
            "downsampling_factor=np.float32(0.17165487)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21775825)\n",
            "downsampling_factor=np.float32(0.17795353)\n",
            "downsampling_factor=np.float32(0.47382388)\n",
            "downsampling_factor=np.float32(0.24442323)\n",
            "downsampling_factor=np.float32(0.3233966)\n",
            "downsampling_factor=np.float32(0.355123)\n",
            "downsampling_factor=np.float32(0.256944)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "475.5687749385834\n",
            "downsampling_factor=np.float32(1.0308775)\n",
            "downsampling_factor=np.float32(0.4189493)\n",
            "downsampling_factor=np.float32(0.3622759)\n",
            "downsampling_factor=np.float32(0.4507618)\n",
            "downsampling_factor=np.float32(0.37093678)\n",
            "downsampling_factor=np.float32(0.31193954)\n",
            "downsampling_factor=np.float32(0.31081405)\n",
            "downsampling_factor=np.float32(0.22766624)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.1649081)\n",
            "downsampling_factor=np.float32(0.22894077)\n",
            "downsampling_factor=np.float32(0.5006331)\n",
            "downsampling_factor=np.float32(0.31920105)\n",
            "downsampling_factor=np.float32(0.25877953)\n",
            "downsampling_factor=np.float32(0.29471058)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "493.04982471466064\n",
            "downsampling_factor=np.float32(0.83818406)\n",
            "downsampling_factor=np.float32(0.3690166)\n",
            "downsampling_factor=np.float32(0.36279)\n",
            "downsampling_factor=np.float32(0.44937256)\n",
            "downsampling_factor=np.float32(0.37067822)\n",
            "downsampling_factor=np.float32(0.29160085)\n",
            "downsampling_factor=np.float32(0.17338395)\n",
            "downsampling_factor=np.float32(0.2168945)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.4607762)\n",
            "downsampling_factor=np.float32(0.1955144)\n",
            "downsampling_factor=np.float32(0.4968564)\n",
            "downsampling_factor=np.float32(0.36259544)\n",
            "downsampling_factor=np.float32(0.3424889)\n",
            "downsampling_factor=np.float32(0.24000733)\n",
            "downsampling_factor=np.float32(0.25949892)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "511.14752316474915\n",
            "downsampling_factor=np.float32(0.85584784)\n",
            "downsampling_factor=np.float32(0.4275846)\n",
            "downsampling_factor=np.float32(0.3626027)\n",
            "downsampling_factor=np.float32(0.44639078)\n",
            "downsampling_factor=np.float32(0.3715255)\n",
            "downsampling_factor=np.float32(0.30039248)\n",
            "downsampling_factor=np.float32(0.1718347)\n",
            "downsampling_factor=np.float32(0.21571226)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.45736516)\n",
            "downsampling_factor=np.float32(0.19070911)\n",
            "downsampling_factor=np.float32(0.49914575)\n",
            "downsampling_factor=np.float32(0.36253956)\n",
            "downsampling_factor=np.float32(0.3349773)\n",
            "downsampling_factor=np.float32(0.25684842)\n",
            "downsampling_factor=np.float32(0.23150954)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "529.3354532718658\n",
            "downsampling_factor=np.float32(1.4088058)\n",
            "downsampling_factor=np.float32(0.38567346)\n",
            "downsampling_factor=np.float32(0.38299763)\n",
            "downsampling_factor=np.float32(0.38199732)\n",
            "downsampling_factor=np.float32(0.32199034)\n",
            "downsampling_factor=np.float32(0.46578535)\n",
            "downsampling_factor=np.float32(0.23576613)\n",
            "downsampling_factor=np.float32(0.21202254)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17136781)\n",
            "downsampling_factor=np.float32(0.32536143)\n",
            "downsampling_factor=np.float32(0.28315496)\n",
            "downsampling_factor=np.float32(0.49920586)\n",
            "downsampling_factor=np.float32(0.33705667)\n",
            "downsampling_factor=np.float32(0.22817254)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "546.3742287158966\n",
            "downsampling_factor=np.float32(5.407114)\n",
            "downsampling_factor=np.float32(2.0440006)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "551.9608886241913\n",
            "downsampling_factor=np.float32(5.2929287)\n",
            "downsampling_factor=np.float32(2.3555906)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "557.4527554512024\n",
            "downsampling_factor=np.float32(0.85245055)\n",
            "downsampling_factor=np.float32(0.42141783)\n",
            "downsampling_factor=np.float32(0.36215627)\n",
            "downsampling_factor=np.float32(0.44626105)\n",
            "downsampling_factor=np.float32(0.3704142)\n",
            "downsampling_factor=np.float32(0.30012035)\n",
            "downsampling_factor=np.float32(0.17124343)\n",
            "downsampling_factor=np.float32(0.21453074)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.45364293)\n",
            "downsampling_factor=np.float32(0.19009049)\n",
            "downsampling_factor=np.float32(0.4896019)\n",
            "downsampling_factor=np.float32(0.36680865)\n",
            "downsampling_factor=np.float32(0.2470572)\n",
            "downsampling_factor=np.float32(0.33995438)\n",
            "downsampling_factor=np.float32(0.25774774)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "575.8785517215729\n",
            "downsampling_factor=np.float32(2.9362051)\n",
            "downsampling_factor=np.float32(0.51583356)\n",
            "downsampling_factor=np.float32(0.56641895)\n",
            "downsampling_factor=np.float32(0.41933408)\n",
            "downsampling_factor=np.float32(0.5778777)\n",
            "downsampling_factor=np.float32(0.3326117)\n",
            "downsampling_factor=np.float32(0.4408226)\n",
            "downsampling_factor=np.float32(0.36772028)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.43183905)\n",
            "downsampling_factor=np.float32(0.4441879)\n",
            "downsampling_factor=np.float32(0.6440707)\n",
            "downsampling_factor=np.float32(0.5695947)\n",
            "downsampling_factor=np.float32(0.48769507)\n",
            "downsampling_factor=np.float32(0.29443166)\n",
            "downsampling_factor=np.float32(0.4145697)\n",
            "downsampling_factor=np.float32(0.51093227)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.32539478)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "596.0429809093475\n",
            "downsampling_factor=np.float32(3.701339)\n",
            "downsampling_factor=np.float32(1.3272433)\n",
            "downsampling_factor=np.float32(0.8771623)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "602.3259201049805\n",
            "downsampling_factor=np.float32(0.8809452)\n",
            "downsampling_factor=np.float32(0.4095885)\n",
            "downsampling_factor=np.float32(0.3768002)\n",
            "downsampling_factor=np.float32(0.44737753)\n",
            "downsampling_factor=np.float32(0.3656374)\n",
            "downsampling_factor=np.float32(0.292174)\n",
            "downsampling_factor=np.float32(0.17115887)\n",
            "downsampling_factor=np.float32(0.37474453)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.20293939)\n",
            "downsampling_factor=np.float32(0.21896802)\n",
            "downsampling_factor=np.float32(0.48414156)\n",
            "downsampling_factor=np.float32(0.23780154)\n",
            "downsampling_factor=np.float32(0.32939404)\n",
            "downsampling_factor=np.float32(0.3561481)\n",
            "downsampling_factor=np.float32(0.24916776)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "621.1108617782593\n",
            "downsampling_factor=np.float32(3.8295221)\n",
            "downsampling_factor=np.float32(1.2391274)\n",
            "downsampling_factor=np.float32(1.9145098)\n",
            "downsampling_factor=np.float32(0.86589026)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "628.5103261470795\n",
            "downsampling_factor=np.float32(0.8099985)\n",
            "downsampling_factor=np.float32(0.3770067)\n",
            "downsampling_factor=np.float32(0.36858484)\n",
            "downsampling_factor=np.float32(0.44877893)\n",
            "downsampling_factor=np.float32(0.3690449)\n",
            "downsampling_factor=np.float32(0.28659073)\n",
            "downsampling_factor=np.float32(0.1706167)\n",
            "downsampling_factor=np.float32(0.4455253)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21891437)\n",
            "downsampling_factor=np.float32(0.19514863)\n",
            "downsampling_factor=np.float32(0.47584894)\n",
            "downsampling_factor=np.float32(0.24719055)\n",
            "downsampling_factor=np.float32(0.32366535)\n",
            "downsampling_factor=np.float32(0.35838342)\n",
            "downsampling_factor=np.float32(0.2544258)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "647.3803131580353\n",
            "downsampling_factor=np.float32(0.75641465)\n",
            "downsampling_factor=np.float32(0.48980367)\n",
            "downsampling_factor=np.float32(0.38669655)\n",
            "downsampling_factor=np.float32(0.38899153)\n",
            "downsampling_factor=np.float32(0.22626321)\n",
            "downsampling_factor=np.float32(0.46811783)\n",
            "downsampling_factor=np.float32(0.21525116)\n",
            "downsampling_factor=np.float32(0.17264327)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.34224162)\n",
            "downsampling_factor=np.float32(0.25657454)\n",
            "downsampling_factor=np.float32(0.50601554)\n",
            "downsampling_factor=np.float32(0.40434965)\n",
            "downsampling_factor=np.float32(0.33507046)\n",
            "downsampling_factor=np.float32(0.22474688)\n",
            "downsampling_factor=np.float32(0.2752461)\n",
            "downsampling_factor=np.float32(0.5109534)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "666.1551983356476\n",
            "downsampling_factor=np.float32(0.9189698)\n",
            "downsampling_factor=np.float32(0.42873317)\n",
            "downsampling_factor=np.float32(0.36314148)\n",
            "downsampling_factor=np.float32(0.36731523)\n",
            "downsampling_factor=np.float32(0.45033455)\n",
            "downsampling_factor=np.float32(0.30930042)\n",
            "downsampling_factor=np.float32(0.32408762)\n",
            "downsampling_factor=np.float32(0.22715396)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.16301514)\n",
            "downsampling_factor=np.float32(0.2130919)\n",
            "downsampling_factor=np.float32(0.49480546)\n",
            "downsampling_factor=np.float32(0.31927216)\n",
            "downsampling_factor=np.float32(0.25288033)\n",
            "downsampling_factor=np.float32(0.2613297)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "683.8306243419647\n",
            "downsampling_factor=np.float32(1.4383494)\n",
            "downsampling_factor=np.float32(0.412282)\n",
            "downsampling_factor=np.float32(0.30646595)\n",
            "downsampling_factor=np.float32(0.38463)\n",
            "downsampling_factor=np.float32(0.37642792)\n",
            "downsampling_factor=np.float32(0.45891196)\n",
            "downsampling_factor=np.float32(0.18686862)\n",
            "downsampling_factor=np.float32(0.34721088)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.18739104)\n",
            "downsampling_factor=np.float32(0.23497993)\n",
            "downsampling_factor=np.float32(0.32689333)\n",
            "downsampling_factor=np.float32(0.49828893)\n",
            "downsampling_factor=np.float32(0.33926988)\n",
            "downsampling_factor=np.float32(0.32652456)\n",
            "downsampling_factor=np.float32(0.2688425)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "701.783460855484\n",
            "downsampling_factor=np.float32(3.0913353)\n",
            "downsampling_factor=np.float32(1.2602068)\n",
            "downsampling_factor=np.float32(0.5961094)\n",
            "downsampling_factor=np.float32(0.38611063)\n",
            "downsampling_factor=np.float32(0.5575568)\n",
            "downsampling_factor=np.float32(0.4279461)\n",
            "downsampling_factor=np.float32(0.5143216)\n",
            "downsampling_factor=np.float32(0.37544313)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.59183437)\n",
            "downsampling_factor=np.float32(0.28013867)\n",
            "downsampling_factor=np.float32(0.45051703)\n",
            "downsampling_factor=np.float32(0.4817861)\n",
            "downsampling_factor=np.float32(0.46462408)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "718.690411567688\n",
            "downsampling_factor=np.float32(1.207634)\n",
            "downsampling_factor=np.float32(3.1059132)\n",
            "downsampling_factor=np.float32(0.77104634)\n",
            "downsampling_factor=np.float32(0.5444374)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "725.9578514099121\n",
            "downsampling_factor=np.float32(0.7179084)\n",
            "downsampling_factor=np.float32(0.39263025)\n",
            "downsampling_factor=np.float32(0.36254725)\n",
            "downsampling_factor=np.float32(0.4490526)\n",
            "downsampling_factor=np.float32(0.37032712)\n",
            "downsampling_factor=np.float32(0.17118485)\n",
            "downsampling_factor=np.float32(0.29360867)\n",
            "downsampling_factor=np.float32(0.21463098)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.46063626)\n",
            "downsampling_factor=np.float32(0.19254327)\n",
            "downsampling_factor=np.float32(0.4846816)\n",
            "downsampling_factor=np.float32(0.3657578)\n",
            "downsampling_factor=np.float32(0.24378459)\n",
            "downsampling_factor=np.float32(0.33563685)\n",
            "downsampling_factor=np.float32(0.25299025)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "744.888475894928\n",
            "downsampling_factor=np.float32(0.43560654)\n",
            "downsampling_factor=np.float32(0.872888)\n",
            "downsampling_factor=np.float32(0.38267308)\n",
            "downsampling_factor=np.float32(0.37896508)\n",
            "downsampling_factor=np.float32(0.46640906)\n",
            "downsampling_factor=np.float32(0.3184196)\n",
            "downsampling_factor=np.float32(0.21425112)\n",
            "downsampling_factor=np.float32(0.2368036)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17170922)\n",
            "downsampling_factor=np.float32(0.3235296)\n",
            "downsampling_factor=np.float32(0.29172912)\n",
            "downsampling_factor=np.float32(0.50317436)\n",
            "downsampling_factor=np.float32(0.3347768)\n",
            "downsampling_factor=np.float32(0.22943012)\n",
            "downsampling_factor=np.float32(0.2713875)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "762.779816865921\n",
            "downsampling_factor=np.float32(0.89282656)\n",
            "downsampling_factor=np.float32(0.40595818)\n",
            "downsampling_factor=np.float32(0.37024322)\n",
            "downsampling_factor=np.float32(0.36586994)\n",
            "downsampling_factor=np.float32(0.44758478)\n",
            "downsampling_factor=np.float32(0.3040349)\n",
            "downsampling_factor=np.float32(0.3222692)\n",
            "downsampling_factor=np.float32(0.48650646)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.27038202)\n",
            "downsampling_factor=np.float32(0.22269453)\n",
            "downsampling_factor=np.float32(0.17406273)\n",
            "downsampling_factor=np.float32(0.33003527)\n",
            "downsampling_factor=np.float32(0.294511)\n",
            "downsampling_factor=np.float32(0.2726214)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "780.2590382099152\n",
            "downsampling_factor=np.float32(3.9839919)\n",
            "downsampling_factor=np.float32(1.2132925)\n",
            "downsampling_factor=np.float32(0.8215726)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "786.6260285377502\n",
            "downsampling_factor=np.float32(1.0058712)\n",
            "downsampling_factor=np.float32(0.37507308)\n",
            "downsampling_factor=np.float32(0.38310033)\n",
            "downsampling_factor=np.float32(0.3810554)\n",
            "downsampling_factor=np.float32(0.32084084)\n",
            "downsampling_factor=np.float32(0.46671486)\n",
            "downsampling_factor=np.float32(0.21535325)\n",
            "downsampling_factor=np.float32(0.23769514)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17124009)\n",
            "downsampling_factor=np.float32(0.32549033)\n",
            "downsampling_factor=np.float32(0.28839335)\n",
            "downsampling_factor=np.float32(0.50258243)\n",
            "downsampling_factor=np.float32(0.33681908)\n",
            "downsampling_factor=np.float32(0.22702014)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "804.1231224536896\n",
            "downsampling_factor=np.float32(0.6813043)\n",
            "downsampling_factor=np.float32(0.38750648)\n",
            "downsampling_factor=np.float32(0.3615337)\n",
            "downsampling_factor=np.float32(0.44853273)\n",
            "downsampling_factor=np.float32(0.37047723)\n",
            "downsampling_factor=np.float32(0.46276093)\n",
            "downsampling_factor=np.float32(0.17167036)\n",
            "downsampling_factor=np.float32(0.22160663)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.28545555)\n",
            "downsampling_factor=np.float32(0.19272669)\n",
            "downsampling_factor=np.float32(0.49169892)\n",
            "downsampling_factor=np.float32(0.36614025)\n",
            "downsampling_factor=np.float32(0.24591176)\n",
            "downsampling_factor=np.float32(0.3375446)\n",
            "downsampling_factor=np.float32(0.25397298)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "822.3378157615662\n",
            "downsampling_factor=np.float32(3.7834828)\n",
            "downsampling_factor=np.float32(1.5787038)\n",
            "downsampling_factor=np.float32(0.7450116)\n",
            "downsampling_factor=np.float32(1.0867381)\n",
            "downsampling_factor=np.float32(1.071758)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "831.1913735866547\n",
            "downsampling_factor=np.float32(4.0040455)\n",
            "downsampling_factor=np.float32(1.480784)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "836.4672939777374\n",
            "downsampling_factor=np.float32(0.82977486)\n",
            "downsampling_factor=np.float32(0.43294787)\n",
            "downsampling_factor=np.float32(0.3763392)\n",
            "downsampling_factor=np.float32(0.45287317)\n",
            "downsampling_factor=np.float32(0.3702318)\n",
            "downsampling_factor=np.float32(0.28420958)\n",
            "downsampling_factor=np.float32(0.3322314)\n",
            "downsampling_factor=np.float32(0.17356236)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.2201252)\n",
            "downsampling_factor=np.float32(0.20648253)\n",
            "downsampling_factor=np.float32(0.47299773)\n",
            "downsampling_factor=np.float32(0.229123)\n",
            "downsampling_factor=np.float32(0.32704243)\n",
            "downsampling_factor=np.float32(0.3561243)\n",
            "downsampling_factor=np.float32(0.25200865)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "855.130270242691\n",
            "downsampling_factor=np.float32(4.423847)\n",
            "downsampling_factor=np.float32(2.2380502)\n",
            "downsampling_factor=np.float32(1.1979175)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "861.467526435852\n",
            "downsampling_factor=np.float32(0.8924322)\n",
            "downsampling_factor=np.float32(0.37533933)\n",
            "downsampling_factor=np.float32(0.36330765)\n",
            "downsampling_factor=np.float32(0.45234933)\n",
            "downsampling_factor=np.float32(0.36843795)\n",
            "downsampling_factor=np.float32(0.307419)\n",
            "downsampling_factor=np.float32(0.17333658)\n",
            "downsampling_factor=np.float32(0.21780796)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.33468068)\n",
            "downsampling_factor=np.float32(0.18840492)\n",
            "downsampling_factor=np.float32(0.36395788)\n",
            "downsampling_factor=np.float32(0.4878978)\n",
            "downsampling_factor=np.float32(0.34547043)\n",
            "downsampling_factor=np.float32(0.2383857)\n",
            "downsampling_factor=np.float32(0.2627249)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "879.9735536575317\n",
            "downsampling_factor=np.float32(4.610931)\n",
            "downsampling_factor=np.float32(1.4321052)\n",
            "downsampling_factor=np.float32(0.32195154)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "886.1893515586853\n",
            "downsampling_factor=np.float32(0.7979231)\n",
            "downsampling_factor=np.float32(0.36336988)\n",
            "downsampling_factor=np.float32(0.4494754)\n",
            "downsampling_factor=np.float32(0.36369583)\n",
            "downsampling_factor=np.float32(0.37119895)\n",
            "downsampling_factor=np.float32(0.2879232)\n",
            "downsampling_factor=np.float32(0.17284632)\n",
            "downsampling_factor=np.float32(0.45543694)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21599321)\n",
            "downsampling_factor=np.float32(0.20058648)\n",
            "downsampling_factor=np.float32(0.49419495)\n",
            "downsampling_factor=np.float32(0.3603634)\n",
            "downsampling_factor=np.float32(0.3351663)\n",
            "downsampling_factor=np.float32(0.25969127)\n",
            "downsampling_factor=np.float32(0.23039302)\n",
            "downsampling_factor=np.float32(0.46907488)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "905.3999853134155\n",
            "downsampling_factor=np.float32(0.8763072)\n",
            "downsampling_factor=np.float32(0.423412)\n",
            "downsampling_factor=np.float32(0.38433897)\n",
            "downsampling_factor=np.float32(0.38043168)\n",
            "downsampling_factor=np.float32(0.46977484)\n",
            "downsampling_factor=np.float32(0.22807367)\n",
            "downsampling_factor=np.float32(0.17102154)\n",
            "downsampling_factor=np.float32(0.21773544)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.32970938)\n",
            "downsampling_factor=np.float32(0.31896853)\n",
            "downsampling_factor=np.float32(0.49433)\n",
            "downsampling_factor=np.float32(0.2599286)\n",
            "downsampling_factor=np.float32(0.33127344)\n",
            "downsampling_factor=np.float32(0.22458816)\n",
            "downsampling_factor=np.float32(0.27268407)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "923.6752421855927\n",
            "downsampling_factor=np.float32(1.3559557)\n",
            "downsampling_factor=np.float32(0.4664863)\n",
            "downsampling_factor=np.float32(0.37813133)\n",
            "downsampling_factor=np.float32(0.37517568)\n",
            "downsampling_factor=np.float32(0.46859932)\n",
            "downsampling_factor=np.float32(0.21951807)\n",
            "downsampling_factor=np.float32(0.32305273)\n",
            "downsampling_factor=np.float32(0.21585889)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17163451)\n",
            "downsampling_factor=np.float32(0.34709)\n",
            "downsampling_factor=np.float32(0.525859)\n",
            "downsampling_factor=np.float32(0.22764458)\n",
            "downsampling_factor=np.float32(0.3403721)\n",
            "downsampling_factor=np.float32(0.2910584)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "940.7256984710693\n",
            "downsampling_factor=np.float32(0.897662)\n",
            "downsampling_factor=np.float32(0.41721925)\n",
            "downsampling_factor=np.float32(0.3600386)\n",
            "downsampling_factor=np.float32(0.365089)\n",
            "downsampling_factor=np.float32(0.4589068)\n",
            "downsampling_factor=np.float32(0.30483422)\n",
            "downsampling_factor=np.float32(0.17388701)\n",
            "downsampling_factor=np.float32(0.3672018)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.23176754)\n",
            "downsampling_factor=np.float32(0.21259415)\n",
            "downsampling_factor=np.float32(0.49956316)\n",
            "downsampling_factor=np.float32(0.25827467)\n",
            "downsampling_factor=np.float32(0.24524622)\n",
            "downsampling_factor=np.float32(0.3559585)\n",
            "downsampling_factor=np.float32(0.34821066)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "958.8196802139282\n",
            "downsampling_factor=np.float32(0.74355483)\n",
            "downsampling_factor=np.float32(0.37369055)\n",
            "downsampling_factor=np.float32(0.38350016)\n",
            "downsampling_factor=np.float32(0.38043234)\n",
            "downsampling_factor=np.float32(0.4699833)\n",
            "downsampling_factor=np.float32(0.23110564)\n",
            "downsampling_factor=np.float32(0.17105825)\n",
            "downsampling_factor=np.float32(0.31069008)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.2144542)\n",
            "downsampling_factor=np.float32(0.34655538)\n",
            "downsampling_factor=np.float32(0.5011378)\n",
            "downsampling_factor=np.float32(0.26379213)\n",
            "downsampling_factor=np.float32(0.33281234)\n",
            "downsampling_factor=np.float32(0.22421849)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "976.2949125766754\n",
            "downsampling_factor=np.float32(1.0100206)\n",
            "downsampling_factor=np.float32(0.3996671)\n",
            "downsampling_factor=np.float32(0.3829421)\n",
            "downsampling_factor=np.float32(0.45462736)\n",
            "downsampling_factor=np.float32(0.39184624)\n",
            "downsampling_factor=np.float32(0.28607702)\n",
            "downsampling_factor=np.float32(0.34587502)\n",
            "downsampling_factor=np.float32(0.46283397)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.20980126)\n",
            "downsampling_factor=np.float32(0.22975688)\n",
            "downsampling_factor=np.float32(0.19087382)\n",
            "downsampling_factor=np.float32(0.33587366)\n",
            "downsampling_factor=np.float32(0.4870825)\n",
            "downsampling_factor=np.float32(0.3671698)\n",
            "downsampling_factor=np.float32(0.2627829)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "994.3072419166565\n",
            "downsampling_factor=np.float32(4.2179966)\n",
            "downsampling_factor=np.float32(2.1533763)\n",
            "downsampling_factor=np.float32(1.3328929)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1001.1571116447449\n",
            "downsampling_factor=np.float32(0.80736065)\n",
            "downsampling_factor=np.float32(0.35984552)\n",
            "downsampling_factor=np.float32(0.36884642)\n",
            "downsampling_factor=np.float32(0.44936496)\n",
            "downsampling_factor=np.float32(0.37170255)\n",
            "downsampling_factor=np.float32(0.2871418)\n",
            "downsampling_factor=np.float32(0.33583403)\n",
            "downsampling_factor=np.float32(0.17086609)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.22080736)\n",
            "downsampling_factor=np.float32(0.19531517)\n",
            "downsampling_factor=np.float32(0.48532164)\n",
            "downsampling_factor=np.float32(0.24609725)\n",
            "downsampling_factor=np.float32(0.3653613)\n",
            "downsampling_factor=np.float32(0.33147877)\n",
            "downsampling_factor=np.float32(0.253734)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1019.4479877948761\n",
            "downsampling_factor=np.float32(0.7485101)\n",
            "downsampling_factor=np.float32(0.4759109)\n",
            "downsampling_factor=np.float32(0.3824233)\n",
            "downsampling_factor=np.float32(0.38480043)\n",
            "downsampling_factor=np.float32(0.46599007)\n",
            "downsampling_factor=np.float32(0.22274084)\n",
            "downsampling_factor=np.float32(0.21785569)\n",
            "downsampling_factor=np.float32(0.17273569)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.27127817)\n",
            "downsampling_factor=np.float32(0.4511684)\n",
            "downsampling_factor=np.float32(0.4970845)\n",
            "downsampling_factor=np.float32(0.3443823)\n",
            "downsampling_factor=np.float32(0.33726993)\n",
            "downsampling_factor=np.float32(0.22618866)\n",
            "downsampling_factor=np.float32(0.27583998)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1037.9246983528137\n",
            "downsampling_factor=np.float32(0.74963665)\n",
            "downsampling_factor=np.float32(0.4798254)\n",
            "downsampling_factor=np.float32(0.3850597)\n",
            "downsampling_factor=np.float32(0.3843467)\n",
            "downsampling_factor=np.float32(0.46559247)\n",
            "downsampling_factor=np.float32(0.21706851)\n",
            "downsampling_factor=np.float32(0.22186041)\n",
            "downsampling_factor=np.float32(0.17226219)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.49704257)\n",
            "downsampling_factor=np.float32(0.44795465)\n",
            "downsampling_factor=np.float32(0.26305655)\n",
            "downsampling_factor=np.float32(0.34105983)\n",
            "downsampling_factor=np.float32(0.3366046)\n",
            "downsampling_factor=np.float32(0.22630364)\n",
            "downsampling_factor=np.float32(0.27622727)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1056.024587392807\n",
            "downsampling_factor=np.float32(0.7525835)\n",
            "downsampling_factor=np.float32(0.48336917)\n",
            "downsampling_factor=np.float32(0.3829649)\n",
            "downsampling_factor=np.float32(0.3834011)\n",
            "downsampling_factor=np.float32(0.46714112)\n",
            "downsampling_factor=np.float32(0.22570753)\n",
            "downsampling_factor=np.float32(0.21505928)\n",
            "downsampling_factor=np.float32(0.17179516)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.26061994)\n",
            "downsampling_factor=np.float32(0.50077826)\n",
            "downsampling_factor=np.float32(0.44863525)\n",
            "downsampling_factor=np.float32(0.3454771)\n",
            "downsampling_factor=np.float32(0.33534542)\n",
            "downsampling_factor=np.float32(0.22647476)\n",
            "downsampling_factor=np.float32(0.276128)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1074.3020219802856\n",
            "downsampling_factor=np.float32(0.43263435)\n",
            "downsampling_factor=np.float32(0.8039716)\n",
            "downsampling_factor=np.float32(0.37286472)\n",
            "downsampling_factor=np.float32(0.39755702)\n",
            "downsampling_factor=np.float32(0.45516732)\n",
            "downsampling_factor=np.float32(0.31741542)\n",
            "downsampling_factor=np.float32(0.23051266)\n",
            "downsampling_factor=np.float32(0.49576637)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.1919853)\n",
            "downsampling_factor=np.float32(0.21134673)\n",
            "downsampling_factor=np.float32(0.37508297)\n",
            "downsampling_factor=np.float32(0.32950568)\n",
            "downsampling_factor=np.float32(0.3496549)\n",
            "downsampling_factor=np.float32(0.28283757)\n",
            "downsampling_factor=np.float32(0.20240085)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1092.483255147934\n",
            "downsampling_factor=np.float32(0.97633773)\n",
            "downsampling_factor=np.float32(0.4219745)\n",
            "downsampling_factor=np.float32(0.36220688)\n",
            "downsampling_factor=np.float32(0.45241675)\n",
            "downsampling_factor=np.float32(0.3686703)\n",
            "downsampling_factor=np.float32(0.29927763)\n",
            "downsampling_factor=np.float32(0.17453282)\n",
            "downsampling_factor=np.float32(0.22396076)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.3769983)\n",
            "downsampling_factor=np.float32(0.19993035)\n",
            "downsampling_factor=np.float32(0.36904898)\n",
            "downsampling_factor=np.float32(0.49266076)\n",
            "downsampling_factor=np.float32(0.35063204)\n",
            "downsampling_factor=np.float32(0.2605411)\n",
            "downsampling_factor=np.float32(0.25373372)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1110.852932691574\n",
            "downsampling_factor=np.float32(4.4798656)\n",
            "downsampling_factor=np.float32(1.283116)\n",
            "downsampling_factor=np.float32(0.8037319)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1117.0468587875366\n",
            "downsampling_factor=np.float32(0.74293095)\n",
            "downsampling_factor=np.float32(0.43477917)\n",
            "downsampling_factor=np.float32(0.3835641)\n",
            "downsampling_factor=np.float32(0.3795783)\n",
            "downsampling_factor=np.float32(0.46984792)\n",
            "downsampling_factor=np.float32(0.22890258)\n",
            "downsampling_factor=np.float32(0.17139554)\n",
            "downsampling_factor=np.float32(0.21790567)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.32120463)\n",
            "downsampling_factor=np.float32(0.35409677)\n",
            "downsampling_factor=np.float32(0.4944058)\n",
            "downsampling_factor=np.float32(0.2752623)\n",
            "downsampling_factor=np.float32(0.33359954)\n",
            "downsampling_factor=np.float32(0.22521394)\n",
            "downsampling_factor=np.float32(0.27322036)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1135.357828617096\n",
            "downsampling_factor=np.float32(0.59631276)\n",
            "downsampling_factor=np.float32(0.37559542)\n",
            "downsampling_factor=np.float32(0.3830809)\n",
            "downsampling_factor=np.float32(0.38144922)\n",
            "downsampling_factor=np.float32(0.30724224)\n",
            "downsampling_factor=np.float32(0.47013992)\n",
            "downsampling_factor=np.float32(0.22861965)\n",
            "downsampling_factor=np.float32(0.17133348)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21879761)\n",
            "downsampling_factor=np.float32(0.41771218)\n",
            "downsampling_factor=np.float32(0.49450547)\n",
            "downsampling_factor=np.float32(0.2718183)\n",
            "downsampling_factor=np.float32(0.33341226)\n",
            "downsampling_factor=np.float32(0.22471076)\n",
            "downsampling_factor=np.float32(0.27335432)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1153.4973316192627\n",
            "downsampling_factor=np.float32(3.7103977)\n",
            "downsampling_factor=np.float32(0.94850665)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1159.1107983589172\n",
            "downsampling_factor=np.float32(0.8723638)\n",
            "downsampling_factor=np.float32(0.40805545)\n",
            "downsampling_factor=np.float32(0.37815535)\n",
            "downsampling_factor=np.float32(0.44981322)\n",
            "downsampling_factor=np.float32(0.36610064)\n",
            "downsampling_factor=np.float32(0.2868444)\n",
            "downsampling_factor=np.float32(0.37194502)\n",
            "downsampling_factor=np.float32(0.17161576)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.20430891)\n",
            "downsampling_factor=np.float32(0.22091053)\n",
            "downsampling_factor=np.float32(0.48151082)\n",
            "downsampling_factor=np.float32(0.23657463)\n",
            "downsampling_factor=np.float32(0.3283887)\n",
            "downsampling_factor=np.float32(0.35792723)\n",
            "downsampling_factor=np.float32(0.24909253)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1177.3392958641052\n",
            "downsampling_factor=np.float32(0.908643)\n",
            "downsampling_factor=np.float32(0.44704023)\n",
            "downsampling_factor=np.float32(0.38412517)\n",
            "downsampling_factor=np.float32(0.3625113)\n",
            "downsampling_factor=np.float32(0.44787535)\n",
            "downsampling_factor=np.float32(0.46360624)\n",
            "downsampling_factor=np.float32(0.27194628)\n",
            "downsampling_factor=np.float32(0.21742234)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17919318)\n",
            "downsampling_factor=np.float32(0.2066241)\n",
            "downsampling_factor=np.float32(0.4681092)\n",
            "downsampling_factor=np.float32(0.2336663)\n",
            "downsampling_factor=np.float32(0.33153868)\n",
            "downsampling_factor=np.float32(0.25797284)\n",
            "downsampling_factor=np.float32(0.35164773)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1195.7066786289215\n",
            "downsampling_factor=np.float32(0.9147777)\n",
            "downsampling_factor=np.float32(0.46931183)\n",
            "downsampling_factor=np.float32(0.36359856)\n",
            "downsampling_factor=np.float32(0.38685232)\n",
            "downsampling_factor=np.float32(0.5157881)\n",
            "downsampling_factor=np.float32(0.44950593)\n",
            "downsampling_factor=np.float32(0.4690882)\n",
            "downsampling_factor=np.float32(0.2068493)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.18570971)\n",
            "downsampling_factor=np.float32(0.24161565)\n",
            "downsampling_factor=np.float32(0.2511814)\n",
            "downsampling_factor=np.float32(0.3290882)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1210.89892745018\n",
            "downsampling_factor=np.float32(1.1037953)\n",
            "downsampling_factor=np.float32(0.38818967)\n",
            "downsampling_factor=np.float32(0.3832346)\n",
            "downsampling_factor=np.float32(0.3806278)\n",
            "downsampling_factor=np.float32(0.31797615)\n",
            "downsampling_factor=np.float32(0.46857706)\n",
            "downsampling_factor=np.float32(0.23740661)\n",
            "downsampling_factor=np.float32(0.21255715)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17071247)\n",
            "downsampling_factor=np.float32(0.32781124)\n",
            "downsampling_factor=np.float32(0.2929609)\n",
            "downsampling_factor=np.float32(0.5076478)\n",
            "downsampling_factor=np.float32(0.33890668)\n",
            "downsampling_factor=np.float32(0.22686791)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1228.0136997699738\n",
            "downsampling_factor=np.float32(0.81868124)\n",
            "downsampling_factor=np.float32(0.37201887)\n",
            "downsampling_factor=np.float32(0.362816)\n",
            "downsampling_factor=np.float32(0.44919378)\n",
            "downsampling_factor=np.float32(0.37049037)\n",
            "downsampling_factor=np.float32(0.29109445)\n",
            "downsampling_factor=np.float32(0.173213)\n",
            "downsampling_factor=np.float32(0.21574213)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.45300126)\n",
            "downsampling_factor=np.float32(0.19560246)\n",
            "downsampling_factor=np.float32(0.36317316)\n",
            "downsampling_factor=np.float32(0.4897818)\n",
            "downsampling_factor=np.float32(0.34200737)\n",
            "downsampling_factor=np.float32(0.23973767)\n",
            "downsampling_factor=np.float32(0.25814947)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1246.327067375183\n",
            "downsampling_factor=np.float32(2.6757224)\n",
            "downsampling_factor=np.float32(0.5206426)\n",
            "downsampling_factor=np.float32(0.507171)\n",
            "downsampling_factor=np.float32(0.39083385)\n",
            "downsampling_factor=np.float32(0.3654944)\n",
            "downsampling_factor=np.float32(0.33335686)\n",
            "downsampling_factor=np.float32(0.48674235)\n",
            "downsampling_factor=np.float32(0.5856196)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.52320224)\n",
            "downsampling_factor=np.float32(0.5829354)\n",
            "downsampling_factor=np.float32(0.54459095)\n",
            "downsampling_factor=np.float32(0.39823496)\n",
            "downsampling_factor=np.float32(0.3406477)\n",
            "downsampling_factor=np.float32(0.5106416)\n",
            "downsampling_factor=np.float32(0.53355294)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1264.7194757461548\n",
            "downsampling_factor=np.float32(0.85174495)\n",
            "downsampling_factor=np.float32(0.4393262)\n",
            "downsampling_factor=np.float32(0.37530342)\n",
            "downsampling_factor=np.float32(0.45246413)\n",
            "downsampling_factor=np.float32(0.36885083)\n",
            "downsampling_factor=np.float32(0.28182682)\n",
            "downsampling_factor=np.float32(0.33145538)\n",
            "downsampling_factor=np.float32(0.1732847)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.22214893)\n",
            "downsampling_factor=np.float32(0.2015303)\n",
            "downsampling_factor=np.float32(0.4769958)\n",
            "downsampling_factor=np.float32(0.22888216)\n",
            "downsampling_factor=np.float32(0.32930762)\n",
            "downsampling_factor=np.float32(0.3561488)\n",
            "downsampling_factor=np.float32(0.25407025)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1283.0419855117798\n",
            "downsampling_factor=np.float32(0.87858087)\n",
            "downsampling_factor=np.float32(0.4557722)\n",
            "downsampling_factor=np.float32(0.38020426)\n",
            "downsampling_factor=np.float32(0.36543927)\n",
            "downsampling_factor=np.float32(0.44592348)\n",
            "downsampling_factor=np.float32(0.46340442)\n",
            "downsampling_factor=np.float32(0.3031829)\n",
            "downsampling_factor=np.float32(0.20073755)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17315388)\n",
            "downsampling_factor=np.float32(0.22103694)\n",
            "downsampling_factor=np.float32(0.2415249)\n",
            "downsampling_factor=np.float32(0.47846505)\n",
            "downsampling_factor=np.float32(0.33615062)\n",
            "downsampling_factor=np.float32(0.35120967)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1300.1576869487762\n",
            "downsampling_factor=np.float32(0.85157937)\n",
            "downsampling_factor=np.float32(0.42861375)\n",
            "downsampling_factor=np.float32(0.37985045)\n",
            "downsampling_factor=np.float32(0.44788232)\n",
            "downsampling_factor=np.float32(0.36798823)\n",
            "downsampling_factor=np.float32(0.27747837)\n",
            "downsampling_factor=np.float32(0.3550452)\n",
            "downsampling_factor=np.float32(0.17334533)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.20398442)\n",
            "downsampling_factor=np.float32(0.22044493)\n",
            "downsampling_factor=np.float32(0.48292008)\n",
            "downsampling_factor=np.float32(0.23593405)\n",
            "downsampling_factor=np.float32(0.32835528)\n",
            "downsampling_factor=np.float32(0.35322985)\n",
            "downsampling_factor=np.float32(0.2480911)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1318.3103125095367\n",
            "downsampling_factor=np.float32(0.75307465)\n",
            "downsampling_factor=np.float32(0.4829713)\n",
            "downsampling_factor=np.float32(0.3829204)\n",
            "downsampling_factor=np.float32(0.3862689)\n",
            "downsampling_factor=np.float32(0.46659195)\n",
            "downsampling_factor=np.float32(0.22481029)\n",
            "downsampling_factor=np.float32(0.21512254)\n",
            "downsampling_factor=np.float32(0.17140788)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.2582376)\n",
            "downsampling_factor=np.float32(0.501129)\n",
            "downsampling_factor=np.float32(0.44272518)\n",
            "downsampling_factor=np.float32(0.34319702)\n",
            "downsampling_factor=np.float32(0.33530536)\n",
            "downsampling_factor=np.float32(0.22595926)\n",
            "downsampling_factor=np.float32(0.27230605)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1336.6884570121765\n",
            "downsampling_factor=np.float32(0.7507913)\n",
            "downsampling_factor=np.float32(0.48169285)\n",
            "downsampling_factor=np.float32(0.3832265)\n",
            "downsampling_factor=np.float32(0.3839491)\n",
            "downsampling_factor=np.float32(0.4660787)\n",
            "downsampling_factor=np.float32(0.22262089)\n",
            "downsampling_factor=np.float32(0.21664171)\n",
            "downsampling_factor=np.float32(0.17151973)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.49711275)\n",
            "downsampling_factor=np.float32(0.44809818)\n",
            "downsampling_factor=np.float32(0.26323438)\n",
            "downsampling_factor=np.float32(0.34131908)\n",
            "downsampling_factor=np.float32(0.33695564)\n",
            "downsampling_factor=np.float32(0.22635804)\n",
            "downsampling_factor=np.float32(0.27607435)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1354.864138841629\n",
            "downsampling_factor=np.float32(0.89868355)\n",
            "downsampling_factor=np.float32(0.44729832)\n",
            "downsampling_factor=np.float32(0.388784)\n",
            "downsampling_factor=np.float32(0.36287013)\n",
            "downsampling_factor=np.float32(0.4491469)\n",
            "downsampling_factor=np.float32(0.464036)\n",
            "downsampling_factor=np.float32(0.2735815)\n",
            "downsampling_factor=np.float32(0.18947975)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21687281)\n",
            "downsampling_factor=np.float32(0.20438807)\n",
            "downsampling_factor=np.float32(0.46759233)\n",
            "downsampling_factor=np.float32(0.23572123)\n",
            "downsampling_factor=np.float32(0.25216547)\n",
            "downsampling_factor=np.float32(0.330713)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1371.9893577098846\n",
            "downsampling_factor=np.float32(2.7842405)\n",
            "downsampling_factor=np.float32(0.50866956)\n",
            "downsampling_factor=np.float32(0.55647916)\n",
            "downsampling_factor=np.float32(0.36062685)\n",
            "downsampling_factor=np.float32(0.61329716)\n",
            "downsampling_factor=np.float32(0.56378967)\n",
            "downsampling_factor=np.float32(0.32308674)\n",
            "downsampling_factor=np.float32(0.59621686)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.4361019)\n",
            "downsampling_factor=np.float32(0.39857864)\n",
            "downsampling_factor=np.float32(0.5134735)\n",
            "downsampling_factor=np.float32(0.38961855)\n",
            "downsampling_factor=np.float32(0.27522025)\n",
            "downsampling_factor=np.float32(0.4887832)\n",
            "downsampling_factor=np.float32(0.56242496)\n",
            "downsampling_factor=np.float32(0.52210283)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.5124922)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1392.4330124855042\n",
            "downsampling_factor=np.float32(2.7950292)\n",
            "downsampling_factor=np.float32(0.51252747)\n",
            "downsampling_factor=np.float32(0.5767911)\n",
            "downsampling_factor=np.float32(0.60493594)\n",
            "downsampling_factor=np.float32(0.3584169)\n",
            "downsampling_factor=np.float32(0.33514372)\n",
            "downsampling_factor=np.float32(0.6063391)\n",
            "downsampling_factor=np.float32(0.53084815)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.5780339)\n",
            "downsampling_factor=np.float32(0.3648424)\n",
            "downsampling_factor=np.float32(0.36070824)\n",
            "downsampling_factor=np.float32(0.44246197)\n",
            "downsampling_factor=np.float32(0.4116999)\n",
            "downsampling_factor=np.float32(0.32037926)\n",
            "downsampling_factor=np.float32(0.50169754)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1411.4550695419312\n",
            "downsampling_factor=np.float32(0.88996935)\n",
            "downsampling_factor=np.float32(0.41844863)\n",
            "downsampling_factor=np.float32(0.3781976)\n",
            "downsampling_factor=np.float32(0.44621786)\n",
            "downsampling_factor=np.float32(0.3659732)\n",
            "downsampling_factor=np.float32(0.29449987)\n",
            "downsampling_factor=np.float32(0.45583522)\n",
            "downsampling_factor=np.float32(0.17096297)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.20156236)\n",
            "downsampling_factor=np.float32(0.21916348)\n",
            "downsampling_factor=np.float32(0.48295432)\n",
            "downsampling_factor=np.float32(0.23955849)\n",
            "downsampling_factor=np.float32(0.330381)\n",
            "downsampling_factor=np.float32(0.35375634)\n",
            "downsampling_factor=np.float32(0.25210848)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1429.671489238739\n",
            "downsampling_factor=np.float32(0.7653687)\n",
            "downsampling_factor=np.float32(0.55768716)\n",
            "downsampling_factor=np.float32(0.38673675)\n",
            "downsampling_factor=np.float32(0.38602376)\n",
            "downsampling_factor=np.float32(0.22785616)\n",
            "downsampling_factor=np.float32(0.46771598)\n",
            "downsampling_factor=np.float32(0.2166857)\n",
            "downsampling_factor=np.float32(0.17149752)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.34222507)\n",
            "downsampling_factor=np.float32(0.5059844)\n",
            "downsampling_factor=np.float32(0.38032356)\n",
            "downsampling_factor=np.float32(0.24291706)\n",
            "downsampling_factor=np.float32(0.33400592)\n",
            "downsampling_factor=np.float32(0.22361821)\n",
            "downsampling_factor=np.float32(0.5121875)\n",
            "downsampling_factor=np.float32(0.2744681)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1449.358913898468\n",
            "downsampling_factor=np.float32(0.76285386)\n",
            "downsampling_factor=np.float32(0.41630435)\n",
            "downsampling_factor=np.float32(0.44563356)\n",
            "downsampling_factor=np.float32(0.36099827)\n",
            "downsampling_factor=np.float32(0.37069952)\n",
            "downsampling_factor=np.float32(0.30416963)\n",
            "downsampling_factor=np.float32(0.17154019)\n",
            "downsampling_factor=np.float32(0.21455999)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.3115004)\n",
            "downsampling_factor=np.float32(0.1906259)\n",
            "downsampling_factor=np.float32(0.49356842)\n",
            "downsampling_factor=np.float32(0.36628902)\n",
            "downsampling_factor=np.float32(0.24620104)\n",
            "downsampling_factor=np.float32(0.3405775)\n",
            "downsampling_factor=np.float32(0.25777853)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1467.3466129302979\n",
            "downsampling_factor=np.float32(1.4297308)\n",
            "downsampling_factor=np.float32(0.3940207)\n",
            "downsampling_factor=np.float32(0.3789112)\n",
            "downsampling_factor=np.float32(0.36849976)\n",
            "downsampling_factor=np.float32(0.47542572)\n",
            "downsampling_factor=np.float32(0.2254328)\n",
            "downsampling_factor=np.float32(0.187169)\n",
            "downsampling_factor=np.float32(0.2130593)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.52095294)\n",
            "downsampling_factor=np.float32(0.49234357)\n",
            "downsampling_factor=np.float32(0.24603517)\n",
            "downsampling_factor=np.float32(0.40947232)\n",
            "downsampling_factor=np.float32(0.29106334)\n",
            "downsampling_factor=np.float32(0.51616305)\n",
            "downsampling_factor=np.float32(0.44179788)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1486.0018658638\n",
            "downsampling_factor=np.float32(0.81544167)\n",
            "downsampling_factor=np.float32(0.42768732)\n",
            "downsampling_factor=np.float32(0.3851301)\n",
            "downsampling_factor=np.float32(0.37732834)\n",
            "downsampling_factor=np.float32(0.4698913)\n",
            "downsampling_factor=np.float32(0.29209486)\n",
            "downsampling_factor=np.float32(0.23041113)\n",
            "downsampling_factor=np.float32(0.2115014)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.17091411)\n",
            "downsampling_factor=np.float32(0.34179115)\n",
            "downsampling_factor=np.float32(0.28553113)\n",
            "downsampling_factor=np.float32(0.4954521)\n",
            "downsampling_factor=np.float32(0.22696126)\n",
            "downsampling_factor=np.float32(0.33305767)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1503.0681262016296\n",
            "downsampling_factor=np.float32(4.3077693)\n",
            "downsampling_factor=np.float32(1.554821)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1508.9701001644135\n",
            "downsampling_factor=np.float32(0.74837494)\n",
            "downsampling_factor=np.float32(0.47488868)\n",
            "downsampling_factor=np.float32(0.38444567)\n",
            "downsampling_factor=np.float32(0.38123268)\n",
            "downsampling_factor=np.float32(0.46600088)\n",
            "downsampling_factor=np.float32(0.21673842)\n",
            "downsampling_factor=np.float32(0.22153087)\n",
            "downsampling_factor=np.float32(0.1729984)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.444712)\n",
            "downsampling_factor=np.float32(0.49761966)\n",
            "downsampling_factor=np.float32(0.26761517)\n",
            "downsampling_factor=np.float32(0.34139362)\n",
            "downsampling_factor=np.float32(0.3376405)\n",
            "downsampling_factor=np.float32(0.2256672)\n",
            "downsampling_factor=np.float32(0.27477157)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1527.0800609588623\n",
            "downsampling_factor=np.float32(0.82824516)\n",
            "downsampling_factor=np.float32(0.38279104)\n",
            "downsampling_factor=np.float32(0.3799909)\n",
            "downsampling_factor=np.float32(0.5007643)\n",
            "downsampling_factor=np.float32(0.46793288)\n",
            "downsampling_factor=np.float32(0.23018956)\n",
            "downsampling_factor=np.float32(0.17142718)\n",
            "downsampling_factor=np.float32(0.21320729)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.44327626)\n",
            "downsampling_factor=np.float32(0.34676346)\n",
            "downsampling_factor=np.float32(0.4998929)\n",
            "downsampling_factor=np.float32(0.3332543)\n",
            "downsampling_factor=np.float32(0.2689646)\n",
            "downsampling_factor=np.float32(0.22753179)\n",
            "downsampling_factor=np.float32(0.27197936)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1545.963083267212\n",
            "downsampling_factor=np.float32(0.83658004)\n",
            "downsampling_factor=np.float32(0.35427552)\n",
            "downsampling_factor=np.float32(0.36766735)\n",
            "downsampling_factor=np.float32(0.44923472)\n",
            "downsampling_factor=np.float32(0.37216297)\n",
            "downsampling_factor=np.float32(0.32774)\n",
            "downsampling_factor=np.float32(0.27716604)\n",
            "downsampling_factor=np.float32(0.17119122)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.2196555)\n",
            "downsampling_factor=np.float32(0.19676197)\n",
            "downsampling_factor=np.float32(0.48684525)\n",
            "downsampling_factor=np.float32(0.24949145)\n",
            "downsampling_factor=np.float32(0.36249313)\n",
            "downsampling_factor=np.float32(0.32936588)\n",
            "downsampling_factor=np.float32(0.25588807)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1563.9402296543121\n",
            "downsampling_factor=np.float32(2.8064551)\n",
            "downsampling_factor=np.float32(0.5164401)\n",
            "downsampling_factor=np.float32(0.59385043)\n",
            "downsampling_factor=np.float32(0.3820254)\n",
            "downsampling_factor=np.float32(0.5488551)\n",
            "downsampling_factor=np.float32(0.3914957)\n",
            "downsampling_factor=np.float32(0.31949648)\n",
            "downsampling_factor=np.float32(0.5316019)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.5959377)\n",
            "downsampling_factor=np.float32(0.27872086)\n",
            "downsampling_factor=np.float32(0.42729262)\n",
            "downsampling_factor=np.float32(0.4481974)\n",
            "downsampling_factor=np.float32(0.5556124)\n",
            "downsampling_factor=np.float32(0.3343048)\n",
            "downsampling_factor=np.float32(0.5112912)\n",
            "downsampling_factor=np.float32(0.9030891)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.5317243)\n",
            "downsampling_factor=np.float32(0.47803625)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1585.7147827148438\n",
            "downsampling_factor=np.float32(0.36992544)\n",
            "downsampling_factor=np.float32(0.38360766)\n",
            "downsampling_factor=np.float32(0.38189423)\n",
            "downsampling_factor=np.float32(0.81173086)\n",
            "downsampling_factor=np.float32(0.32286915)\n",
            "downsampling_factor=np.float32(0.46666655)\n",
            "downsampling_factor=np.float32(0.2361768)\n",
            "downsampling_factor=np.float32(0.2116108)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.1711077)\n",
            "downsampling_factor=np.float32(0.32590088)\n",
            "downsampling_factor=np.float32(0.2831687)\n",
            "downsampling_factor=np.float32(0.50061446)\n",
            "downsampling_factor=np.float32(0.33321562)\n",
            "downsampling_factor=np.float32(0.22807603)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1603.3186087608337\n",
            "downsampling_factor=np.float32(3.9159381)\n",
            "downsampling_factor=np.float32(1.3835405)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1608.8642077445984\n",
            "downsampling_factor=np.float32(1.1984876)\n",
            "downsampling_factor=np.float32(0.6032963)\n",
            "downsampling_factor=np.float32(0.3794834)\n",
            "downsampling_factor=np.float32(0.36908057)\n",
            "downsampling_factor=np.float32(0.30962658)\n",
            "downsampling_factor=np.float32(0.21976574)\n",
            "downsampling_factor=np.float32(0.464169)\n",
            "downsampling_factor=np.float32(0.21761595)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.4410907)\n",
            "downsampling_factor=np.float32(0.18920004)\n",
            "downsampling_factor=np.float32(0.50305057)\n",
            "downsampling_factor=np.float32(0.35316157)\n",
            "downsampling_factor=np.float32(0.34004855)\n",
            "downsampling_factor=np.float32(0.2088356)\n",
            "downsampling_factor=np.float32(0.19402432)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1627.4164733886719\n",
            "downsampling_factor=np.float32(0.8151667)\n",
            "downsampling_factor=np.float32(0.40661395)\n",
            "downsampling_factor=np.float32(0.36378098)\n",
            "downsampling_factor=np.float32(0.4493547)\n",
            "downsampling_factor=np.float32(0.37133026)\n",
            "downsampling_factor=np.float32(0.28903565)\n",
            "downsampling_factor=np.float32(0.33978224)\n",
            "downsampling_factor=np.float32(0.171892)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21541375)\n",
            "downsampling_factor=np.float32(0.19180942)\n",
            "downsampling_factor=np.float32(0.49618766)\n",
            "downsampling_factor=np.float32(0.3370316)\n",
            "downsampling_factor=np.float32(0.36388028)\n",
            "downsampling_factor=np.float32(0.2404341)\n",
            "downsampling_factor=np.float32(0.255455)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1646.2415308952332\n",
            "downsampling_factor=np.float32(4.342335)\n",
            "downsampling_factor=np.float32(1.2264909)\n",
            "downsampling_factor=np.float32(0.7895565)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1652.6689829826355\n",
            "downsampling_factor=np.float32(3.0807276)\n",
            "downsampling_factor=np.float32(1.1078427)\n",
            "downsampling_factor=np.float32(0.5814946)\n",
            "downsampling_factor=np.float32(0.5386098)\n",
            "downsampling_factor=np.float32(0.33126703)\n",
            "downsampling_factor=np.float32(0.43284416)\n",
            "downsampling_factor=np.float32(0.4763546)\n",
            "downsampling_factor=np.float32(0.58834773)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.36579576)\n",
            "downsampling_factor=np.float32(0.4642817)\n",
            "downsampling_factor=np.float32(0.48515287)\n",
            "downsampling_factor=np.float32(0.46138445)\n",
            "downsampling_factor=np.float32(0.4916884)\n",
            "downsampling_factor=np.float32(0.38310495)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1670.33828663826\n",
            "downsampling_factor=np.float32(0.82592934)\n",
            "downsampling_factor=np.float32(0.4528583)\n",
            "downsampling_factor=np.float32(0.36979708)\n",
            "downsampling_factor=np.float32(0.38608915)\n",
            "downsampling_factor=np.float32(0.4521909)\n",
            "downsampling_factor=np.float32(0.28939787)\n",
            "downsampling_factor=np.float32(0.18157856)\n",
            "downsampling_factor=np.float32(0.21835393)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.35471308)\n",
            "downsampling_factor=np.float32(0.20674491)\n",
            "downsampling_factor=np.float32(0.49452317)\n",
            "downsampling_factor=np.float32(0.32912147)\n",
            "downsampling_factor=np.float32(0.35533416)\n",
            "downsampling_factor=np.float32(0.17826056)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1687.5626420974731\n",
            "downsampling_factor=np.float32(0.76214147)\n",
            "downsampling_factor=np.float32(0.5713685)\n",
            "downsampling_factor=np.float32(0.3865536)\n",
            "downsampling_factor=np.float32(0.38616166)\n",
            "downsampling_factor=np.float32(0.22842614)\n",
            "downsampling_factor=np.float32(0.467761)\n",
            "downsampling_factor=np.float32(0.21530251)\n",
            "downsampling_factor=np.float32(0.17061406)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.50387645)\n",
            "downsampling_factor=np.float32(0.34210286)\n",
            "downsampling_factor=np.float32(0.24504352)\n",
            "downsampling_factor=np.float32(0.39342037)\n",
            "downsampling_factor=np.float32(0.33483955)\n",
            "downsampling_factor=np.float32(0.2235267)\n",
            "downsampling_factor=np.float32(0.5139837)\n",
            "downsampling_factor=np.float32(0.2750883)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1707.020046710968\n",
            "downsampling_factor=np.float32(0.79905295)\n",
            "downsampling_factor=np.float32(0.35270548)\n",
            "downsampling_factor=np.float32(0.36323738)\n",
            "downsampling_factor=np.float32(0.44939023)\n",
            "downsampling_factor=np.float32(0.37107104)\n",
            "downsampling_factor=np.float32(0.29041243)\n",
            "downsampling_factor=np.float32(0.17291188)\n",
            "downsampling_factor=np.float32(0.4284637)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.21598144)\n",
            "downsampling_factor=np.float32(0.19848275)\n",
            "downsampling_factor=np.float32(0.49533522)\n",
            "downsampling_factor=np.float32(0.35955346)\n",
            "downsampling_factor=np.float32(0.33852825)\n",
            "downsampling_factor=np.float32(0.2579526)\n",
            "downsampling_factor=np.float32(0.2386264)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1725.2603316307068\n",
            "downsampling_factor=np.float32(0.90858984)\n",
            "downsampling_factor=np.float32(0.4457389)\n",
            "downsampling_factor=np.float32(0.38413137)\n",
            "downsampling_factor=np.float32(0.3630593)\n",
            "downsampling_factor=np.float32(0.44800124)\n",
            "downsampling_factor=np.float32(0.46470585)\n",
            "downsampling_factor=np.float32(0.2752185)\n",
            "downsampling_factor=np.float32(0.21865594)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.18332084)\n",
            "downsampling_factor=np.float32(0.20966248)\n",
            "downsampling_factor=np.float32(0.46732432)\n",
            "downsampling_factor=np.float32(0.23608601)\n",
            "downsampling_factor=np.float32(0.25640962)\n",
            "downsampling_factor=np.float32(0.33144444)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1742.4036972522736\n",
            "downsampling_factor=np.float32(5.173218)\n",
            "downsampling_factor=np.float32(1.6749287)\n",
            "downsampling_factor=np.float32(1.3464608)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1748.6818778514862\n",
            "downsampling_factor=np.float32(0.82202786)\n",
            "downsampling_factor=np.float32(0.41677332)\n",
            "downsampling_factor=np.float32(0.36356574)\n",
            "downsampling_factor=np.float32(0.45067346)\n",
            "downsampling_factor=np.float32(0.37152773)\n",
            "downsampling_factor=np.float32(0.29644284)\n",
            "downsampling_factor=np.float32(0.17286642)\n",
            "downsampling_factor=np.float32(0.21961021)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.42972985)\n",
            "downsampling_factor=np.float32(0.19105347)\n",
            "downsampling_factor=np.float32(0.49570078)\n",
            "downsampling_factor=np.float32(0.3639914)\n",
            "downsampling_factor=np.float32(0.33773336)\n",
            "downsampling_factor=np.float32(0.25658765)\n",
            "downsampling_factor=np.float32(0.23801987)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1767.3504266738892\n",
            "downsampling_factor=np.float32(0.7670944)\n",
            "downsampling_factor=np.float32(0.5352233)\n",
            "downsampling_factor=np.float32(0.38441974)\n",
            "downsampling_factor=np.float32(0.3813826)\n",
            "downsampling_factor=np.float32(0.46762893)\n",
            "downsampling_factor=np.float32(0.23209529)\n",
            "downsampling_factor=np.float32(0.21373491)\n",
            "downsampling_factor=np.float32(0.17016646)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.34355307)\n",
            "downsampling_factor=np.float32(0.5010389)\n",
            "downsampling_factor=np.float32(0.24988906)\n",
            "downsampling_factor=np.float32(0.3888073)\n",
            "downsampling_factor=np.float32(0.33088014)\n",
            "downsampling_factor=np.float32(0.22661583)\n",
            "downsampling_factor=np.float32(0.5146343)\n",
            "downsampling_factor=np.float32(0.27355346)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1786.9534842967987\n",
            "downsampling_factor=np.float32(0.78191495)\n",
            "downsampling_factor=np.float32(0.573434)\n",
            "downsampling_factor=np.float32(0.38531157)\n",
            "downsampling_factor=np.float32(0.38119254)\n",
            "downsampling_factor=np.float32(0.46762693)\n",
            "downsampling_factor=np.float32(0.22829962)\n",
            "downsampling_factor=np.float32(0.21609347)\n",
            "downsampling_factor=np.float32(0.17087579)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.43118206)\n",
            "downsampling_factor=np.float32(0.34626278)\n",
            "downsampling_factor=np.float32(0.50191325)\n",
            "downsampling_factor=np.float32(0.24001808)\n",
            "downsampling_factor=np.float32(0.33422366)\n",
            "downsampling_factor=np.float32(0.22641987)\n",
            "downsampling_factor=np.float32(0.27484545)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1805.3634395599365\n",
            "downsampling_factor=np.float32(1.0482472)\n",
            "downsampling_factor=np.float32(0.43348944)\n",
            "downsampling_factor=np.float32(0.3619234)\n",
            "downsampling_factor=np.float32(0.4458593)\n",
            "downsampling_factor=np.float32(0.37049216)\n",
            "downsampling_factor=np.float32(0.17135556)\n",
            "downsampling_factor=np.float32(0.22324507)\n",
            "downsampling_factor=np.float32(0.28338847)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.45509303)\n",
            "downsampling_factor=np.float32(0.19072115)\n",
            "downsampling_factor=np.float32(0.36693767)\n",
            "downsampling_factor=np.float32(0.4832943)\n",
            "downsampling_factor=np.float32(0.24688554)\n",
            "downsampling_factor=np.float32(0.33861414)\n",
            "downsampling_factor=np.float32(0.25778142)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1824.201741695404\n",
            "downsampling_factor=np.float32(4.6359773)\n",
            "downsampling_factor=np.float32(0.7955144)\n",
            "downsampling_factor=np.float32(0.9219057)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1830.6068727970123\n",
            "downsampling_factor=np.float32(0.88411874)\n",
            "downsampling_factor=np.float32(0.39862996)\n",
            "downsampling_factor=np.float32(0.38493055)\n",
            "downsampling_factor=np.float32(0.37774196)\n",
            "downsampling_factor=np.float32(0.30574384)\n",
            "downsampling_factor=np.float32(0.47058487)\n",
            "downsampling_factor=np.float32(0.2324291)\n",
            "downsampling_factor=np.float32(0.21109097)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.16971214)\n",
            "downsampling_factor=np.float32(0.34633255)\n",
            "downsampling_factor=np.float32(0.50066316)\n",
            "downsampling_factor=np.float32(0.27738523)\n",
            "downsampling_factor=np.float32(0.3387153)\n",
            "downsampling_factor=np.float32(0.22763751)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1848.410319328308\n",
            "downsampling_factor=np.float32(0.8265043)\n",
            "downsampling_factor=np.float32(0.35566503)\n",
            "downsampling_factor=np.float32(0.36983356)\n",
            "downsampling_factor=np.float32(0.4491278)\n",
            "downsampling_factor=np.float32(0.37229005)\n",
            "downsampling_factor=np.float32(0.3351617)\n",
            "downsampling_factor=np.float32(0.288691)\n",
            "downsampling_factor=np.float32(0.17105842)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.22021383)\n",
            "downsampling_factor=np.float32(0.19577551)\n",
            "downsampling_factor=np.float32(0.4856037)\n",
            "downsampling_factor=np.float32(0.24734457)\n",
            "downsampling_factor=np.float32(0.3632834)\n",
            "downsampling_factor=np.float32(0.3308319)\n",
            "downsampling_factor=np.float32(0.25536168)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1866.4485297203064\n",
            "downsampling_factor=np.float32(1.058578)\n",
            "downsampling_factor=np.float32(0.44218743)\n",
            "downsampling_factor=np.float32(0.3617054)\n",
            "downsampling_factor=np.float32(0.44615236)\n",
            "downsampling_factor=np.float32(0.3700521)\n",
            "downsampling_factor=np.float32(0.45818892)\n",
            "downsampling_factor=np.float32(0.17188954)\n",
            "downsampling_factor=np.float32(0.22174798)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.28356794)\n",
            "downsampling_factor=np.float32(0.19029243)\n",
            "downsampling_factor=np.float32(0.3655626)\n",
            "downsampling_factor=np.float32(0.24440193)\n",
            "downsampling_factor=np.float32(0.4876141)\n",
            "downsampling_factor=np.float32(0.33849034)\n",
            "downsampling_factor=np.float32(0.25422382)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1885.1084685325623\n",
            "downsampling_factor=np.float32(0.8406358)\n",
            "downsampling_factor=np.float32(0.3686607)\n",
            "downsampling_factor=np.float32(0.36287662)\n",
            "downsampling_factor=np.float32(0.44919673)\n",
            "downsampling_factor=np.float32(0.37067378)\n",
            "downsampling_factor=np.float32(0.29123273)\n",
            "downsampling_factor=np.float32(0.17317756)\n",
            "downsampling_factor=np.float32(0.21721022)\n",
            "/content/4D-Humans/demo.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  white_img = (torch.ones_like(batch['img'][n]).cpu() - DEFAULT_MEAN[:,None,None]/255) / (DEFAULT_STD[:,None,None]/255)\n",
            "/content/4D-Humans/demo.py:107: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  input_patch = batch['img'][n].cpu() * (DEFAULT_STD[:,None,None]/255) + (DEFAULT_MEAN[:,None,None]/255)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "downsampling_factor=np.float32(0.44552708)\n",
            "downsampling_factor=np.float32(0.19326954)\n",
            "downsampling_factor=np.float32(0.49589303)\n",
            "downsampling_factor=np.float32(0.36366615)\n",
            "downsampling_factor=np.float32(0.33970714)\n",
            "downsampling_factor=np.float32(0.23244312)\n",
            "downsampling_factor=np.float32(0.25947812)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "(6890, 3) (3,)\n",
            "1902.909794807434\n",
            "downsampling_factor=np.float32(0.9056423)\n",
            "downsampling_factor=np.float32(0.38419294)\n",
            "downsampling_factor=np.float32(0.36085814)\n",
            "downsampling_factor=np.float32(0.44986472)\n",
            "downsampling_factor=np.float32(0.37069982)\n",
            "downsampling_factor=np.float32(0.29519495)\n",
            "downsampling_factor=np.float32(0.17358486)\n",
            "downsampling_factor=np.float32(0.21814248)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/4D-Humans\n",
        "\n",
        "# Replace the path to --checkpoint with the specific path we created\n",
        "!python demo.py \\\n",
        "    --checkpoint logs/train/multiruns/hmr2/0/checkpoints/epoch=35-step=1000000.ckpt \\\n",
        "    --img_folder example_data/images \\\n",
        "    --out_folder demo_out \\\n",
        "    --batch_size 16 \\\n",
        "    --side_view \\\n",
        "    --full_frame \\\n",
        "    --save_mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKpHRz1BvdlZ"
      },
      "source": [
        "# Run the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpu-yVB0vw1N",
        "outputId": "840e78fc-380f-488a-a760-2e9b05f494b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading file: hmr2_data.tar.gz\n",
            "Downloading remote file https://people.eecs.berkeley.edu/~jathushan/projects/4dhumans/hmr2_data.tar.gz to /root/.cache/4DHumans/hmr2_data.tar.gz\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/4D-Humans/demo.py\", line 171, in <module>\n",
            "    main()\n",
            "  File \"/content/4D-Humans/demo.py\", line 34, in main\n",
            "    download_models(CACHE_DIR_4DHUMANS)\n",
            "  File \"/content/4D-Humans/hmr2/models/__init__.py\", line 23, in download_models\n",
            "    output = cache_url(url[0], output_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/4D-Humans/hmr2/utils/download.py\", line 65, in cache_url\n",
            "    download_url(url, cache_file_path)\n",
            "  File \"/content/4D-Humans/hmr2/utils/download.py\", line 29, in download_url\n",
            "    response = urlrequest.urlopen(req)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 559, in error\n",
            "    return self._call_chain(*args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 403: Forbidden\n"
          ]
        }
      ],
      "source": [
        "# run hmr2 on a folder of images\n",
        "!python demo.py \\\n",
        "--img_folder example_data/images \\\n",
        "--out_folder demo_out \\\n",
        "--batch_size=48 --side_view --save_mesh \\\n",
        "--checkpoint logs/train/multiruns/hmr2/0/checkpoints/epoch=35-step=1000000.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxwBpN0_CXup",
        "outputId": "96fb71f0-1b9b-4c71-ad05-3faa6e1e6ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading file: hmr2_data.tar.gz\n",
            "Downloading remote file https://people.eecs.berkeley.edu/~jathushan/projects/4dhumans/hmr2_data.tar.gz to /root/.cache/4DHumans/hmr2_data.tar.gz\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/4D-Humans/demo.py\", line 171, in <module>\n",
            "    main()\n",
            "  File \"/content/4D-Humans/demo.py\", line 34, in main\n",
            "    download_models(CACHE_DIR_4DHUMANS)\n",
            "  File \"/content/4D-Humans/hmr2/models/__init__.py\", line 23, in download_models\n",
            "    output = cache_url(url[0], output_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/4D-Humans/hmr2/utils/download.py\", line 65, in cache_url\n",
            "    download_url(url, cache_file_path)\n",
            "  File \"/content/4D-Humans/hmr2/utils/download.py\", line 29, in download_url\n",
            "    response = urlrequest.urlopen(req)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 559, in error\n",
            "    return self._call_chain(*args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 403: Forbidden\n"
          ]
        }
      ],
      "source": [
        "# run hmr2 on a folder of images\n",
        "!python demo.py \\\n",
        "--img_folder example_data/images \\\n",
        "--out_folder demo_out \\\n",
        "--batch_size=48 --side_view --save_mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0BhB4EzwhKb"
      },
      "source": [
        "### Visualize the reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5L3jrsbLwme3",
        "outputId": "289d5820-3585-4997-c8a6-0c0e4236ad05"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'demo_out/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-769967012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# https://colab.research.google.com/drive/1Ex4gE5v1bPR3evfhtG7sDHxQGsWwNwby?usp=sharing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"demo_out/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"demo_out/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\".png\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'demo_out/'"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "# https://colab.research.google.com/drive/1Ex4gE5v1bPR3evfhtG7sDHxQGsWwNwby?usp=sharing\n",
        "output_images = [\"demo_out/\" + i for i in os.listdir(\"demo_out/\") if \".png\" in i]\n",
        "for img in output_images:\n",
        "  display(Image(img))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIL8JadpwE0s"
      },
      "source": [
        "# Video Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVSxpGVrePtl"
      },
      "source": [
        "### Install PHALP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4sNUOQZwG82",
        "outputId": "4e2f08cb-e2a2-4bef-d726-ac4916ad3df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/brjathu/PHALP.git\n",
            "  Cloning https://github.com/brjathu/PHALP.git to /tmp/pip-req-build-milqfstj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/brjathu/PHALP.git /tmp/pip-req-build-milqfstj\n",
            "  Resolved https://github.com/brjathu/PHALP.git to commit 677074a9bd7acac58c0b98a31b04ae54b93dcd2f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting detectron2@ git+https://github.com/facebookresearch/detectron2.git (from phalp==0.1.3)\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-install-xrul_e87/detectron2_5ade1e5e6da84ba79082d32fc143b0a8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-install-xrul_e87/detectron2_5ade1e5e6da84ba79082d32fc143b0a8\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit fd27788985af0f4ca800bca563acdb700bb890e2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytube@ git+https://github.com/pytube/pytube.git (from phalp==0.1.3)\n",
            "  Cloning https://github.com/pytube/pytube.git to /tmp/pip-install-xrul_e87/pytube_34c45d3f361c48c9b00a7d42580ac43f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pytube/pytube.git /tmp/pip-install-xrul_e87/pytube_34c45d3f361c48c9b00a7d42580ac43f\n",
            "  Resolved https://github.com/pytube/pytube.git to commit a32fff39058a6f7e5e59ecd06a7467b71197ce35\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyopengl@ git+https://github.com/mmatl/pyopengl.git (from phalp==0.1.3)\n",
            "  Cloning https://github.com/mmatl/pyopengl.git to /tmp/pip-install-xrul_e87/pyopengl_19a0939b7eec494e9a6de5843abc1cde\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mmatl/pyopengl.git /tmp/pip-install-xrul_e87/pyopengl_19a0939b7eec494e9a6de5843abc1cde\n",
            "  Resolved https://github.com/mmatl/pyopengl.git to commit 76d1261adee2d3fd99b418e75b0416bb7d2865e6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chumpy@ git+https://github.com/mattloper/chumpy (from phalp==0.1.3)\n",
            "  Cloning https://github.com/mattloper/chumpy to /tmp/pip-install-xrul_e87/chumpy_af36e012829b42e49d8ddc16bf7316ae\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mattloper/chumpy /tmp/pip-install-xrul_e87/chumpy_af36e012829b42e49d8ddc16bf7316ae\n",
            "  Resolved https://github.com/mattloper/chumpy to commit 580566eafc9ac68b2614b64d6f7aaa84eebb70da\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting neural-renderer-pytorch@ git+https://github.com/shubham-goel/NMR.git (from phalp==0.1.3)\n",
            "  Cloning https://github.com/shubham-goel/NMR.git to /tmp/pip-install-xrul_e87/neural-renderer-pytorch_8cae724523af4459b7b7db9f5b967b64\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/shubham-goel/NMR.git /tmp/pip-install-xrul_e87/neural-renderer-pytorch_8cae724523af4459b7b7db9f5b967b64\n",
            "  Resolved https://github.com/shubham-goel/NMR.git to commit e990b3c70f48d39231f607c79d76ce3db4bf7483\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (4.13.0.90)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (1.6.1)\n",
            "Requirement already satisfied: pyrender in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (0.1.45)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (0.3.8)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (13.9.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (0.8.2)\n",
            "Collecting scenedetect[opencv] (from phalp==0.1.3)\n",
            "  Downloading scenedetect-0.6.7.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (1.3.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (1.0.24)\n",
            "Collecting av (from phalp==0.1.3)\n",
            "  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: smplx==0.1.28 in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (0.1.28)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from phalp==0.1.3) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.0.1.post2 in /usr/local/lib/python3.12/dist-packages (from smplx==0.1.28->phalp==0.1.3) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from chumpy@ git+https://github.com/mattloper/chumpy->phalp==0.1.3) (1.16.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from chumpy@ git+https://github.com/mattloper/chumpy->phalp==0.1.3) (1.17.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (2.0.11)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.3.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.1.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (2.19.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (2.3.0)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (26.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (25.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core->phalp==0.1.3) (4.9.3)\n",
            "Requirement already satisfied: freetype-py in /usr/local/lib/python3.12/dist-packages (from pyrender->phalp==0.1.3) (2.5.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from pyrender->phalp==0.1.3) (2.37.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pyrender->phalp==0.1.3) (3.6.1)\n",
            "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.12/dist-packages (from pyrender->phalp==0.1.3) (2.1.12)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.12/dist-packages (from pyrender->phalp==0.1.3) (4.11.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->phalp==0.1.3) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->phalp==0.1.3) (2.19.2)\n",
            "Collecting click<8.3.0,~=8.0 (from scenedetect[opencv]->phalp==0.1.3)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from scenedetect[opencv]->phalp==0.1.3) (4.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->phalp==0.1.3) (3.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm->phalp==0.1.3) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm->phalp==0.1.3) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->phalp==0.1.3) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->phalp==0.1.3) (0.7.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->phalp==0.1.3) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (3.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from black->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: pathspec>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (1.0.4)\n",
            "Requirement already satisfied: pytokens>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->phalp==0.1.3) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->phalp==0.1.3) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.10.1)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1.post2->smplx==0.1.28->phalp==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git->phalp==0.1.3) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->phalp==0.1.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->phalp==0.1.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->phalp==0.1.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm->phalp==0.1.3) (2026.1.4)\n",
            "Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scenedetect-0.6.7.1-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: phalp, neural-renderer-pytorch, pytube\n",
            "  Building wheel for phalp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phalp: filename=phalp-0.1.3-py3-none-any.whl size=68082 sha256=40401f8c3d910e09da65f0368cca0ec0e6abd79fb2a515abc85016239b7d0600\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zn5j5wm8/wheels/b7/1d/09/f8be94e04aeab1b715b79ce8805a01d0b0245c82246b759a99\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for neural-renderer-pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for neural-renderer-pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for neural-renderer-pytorch\n",
            "  Building wheel for pytube (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytube: filename=pytube-15.0.0-py3-none-any.whl size=57580 sha256=1fd21048acd54d6e1148873ee3372be1bcaa4041a7ace372c84f37a9cc2151f1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zn5j5wm8/wheels/6e/73/c5/b8c4c774583eebf97698eaba762f2390a8a8dfbca309fa9e5c\n",
            "Successfully built phalp pytube\n",
            "Failed to build neural-renderer-pytorch\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (neural-renderer-pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/brjathu/PHALP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQc_CVQRegJT"
      },
      "source": [
        "### Track and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgkRdPF6yTBC",
        "outputId": "bdc5639f-1efc-4daf-e325-e9f6dc3b1067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/4D-Humans/track.py\", line 13, in <module>\n",
            "    from phalp.configs.base import FullConfig\n",
            "ModuleNotFoundError: No module named 'phalp'\n"
          ]
        }
      ],
      "source": [
        "!python track.py video.source=\"example_data/videos/gymnasts.mp4\" video.start_frame=10 video.end_frame=60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "zGLvO4sz5o2S",
        "outputId": "c5d1aa91-2200-4101-e8a0-e985ffc7886b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31moutputs/PHALP_gymnasts.mp4: No such file or directory\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'outputs/PHALP_gymnasts_ffmpeg.mp4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3846891464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ffmpeg -y -hide_banner -loglevel error -i outputs/PHALP_gymnasts.mp4 outputs/PHALP_gymnasts_ffmpeg.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mshow_local_mp4_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/PHALP_gymnasts_ffmpeg.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m960\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m540\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3846891464.py\u001b[0m in \u001b[0;36mshow_local_mp4_video\u001b[0;34m(file_name, width, height)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mvideo_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n\u001b[1;32m      8\u001b[0m                       \u001b[0;34m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data:video/mp4;base64,{2}\"\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"video/mp4\"\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/PHALP_gymnasts_ffmpeg.mp4'"
          ]
        }
      ],
      "source": [
        "# Display the reconstruction video\n",
        "def show_local_mp4_video(file_name, width=640, height=480):\n",
        "  import io\n",
        "  import base64\n",
        "  from IPython.display import HTML\n",
        "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
        "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
        "                      <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
        "                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n",
        "\n",
        "!ffmpeg -y -hide_banner -loglevel error -i outputs/PHALP_gymnasts.mp4 outputs/PHALP_gymnasts_ffmpeg.mp4\n",
        "show_local_mp4_video('outputs/PHALP_gymnasts_ffmpeg.mp4', width=960, height=540)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}